import time
import base64
import requests
import os
from PIL import Image
from io import BytesIO
from config import Config

OPENAI_AVAILABLE = False
client = None
openai_error_message = ""
openai_last_check = 0

def init_openai():
    """
    Initialize OpenAI client and test model availability.
    Sets OPENAI_AVAILABLE, client, openai_error_message, openai_last_check.
    """
    global OPENAI_AVAILABLE, client, openai_error_message, openai_last_check

    print("ðŸš¨ OPENAI INIT: Starting OpenAI initialization...")

    try:
        from openai import OpenAI
        print("ðŸš¨ OPENAI INIT: OpenAI package imported successfully")

        # Get API key from Config
        api_key = Config.OPENAI_API_KEY
        print(f"ðŸš¨ OPENAI INIT: Config.OPENAI_API_KEY = {api_key[:20]}..." if api_key else "ðŸš¨ OPENAI INIT: Config.OPENAI_API_KEY = None")
        print(f"ðŸš¨ OPENAI INIT: API Key exists: {bool(api_key)}")
        print(f"ðŸš¨ OPENAI INIT: API Key length: {len(api_key) if api_key else 0}")

        if not api_key or api_key == "your-api-key-here":
            openai_error_message = "OpenAI API key not configured"
            print(f"ðŸš¨ OPENAI INIT: âŒ API key check failed - not configured or still default")
            OPENAI_AVAILABLE = False
            return False

        print("ðŸš¨ OPENAI INIT: Creating OpenAI client...")
        client = OpenAI(api_key=api_key)
        print("ðŸš¨ OPENAI INIT: OpenAI client created successfully")

        try:
            print("ðŸš¨ OPENAI INIT: Testing model availability...")
            models = client.models.list()
            model_ids = [m.id for m in models.data]
            print(f"ðŸš¨ OPENAI INIT: Found {len(model_ids)} models")
            print(f"ðŸš¨ OPENAI INIT: First few models: {model_ids[:5]}")

            if "gpt-4o" not in model_ids:
                openai_error_message = "GPT-4o model not available in your account"
                print(f"ðŸš¨ OPENAI INIT: âŒ GPT-4o not found in available models")
                OPENAI_AVAILABLE = False
                return False

            print("ðŸš¨ OPENAI INIT: âœ… GPT-4o model found!")
            OPENAI_AVAILABLE = True
            openai_error_message = ""
            openai_last_check = time.time()
            print("ðŸš¨ OPENAI INIT: âœ… OpenAI initialized successfully!")
            return True

        except Exception as e:
            error_msg = str(e)
            print(f"ðŸš¨ OPENAI INIT: âŒ Model list error: {error_msg}")
            if "insufficient_quota" in error_msg:
                openai_error_message = "Account has no API credits. Please add funds to your OpenAI API account."
            elif "invalid_api_key" in error_msg:
                openai_error_message = "Invalid API key. Please check your OPENAI_API_KEY environment variable."
            elif "rate limit" in error_msg.lower():
                openai_error_message = "Rate limit exceeded. Please try again later."
            else:
                openai_error_message = f"OpenAI API test failed: {error_msg}"
            OPENAI_AVAILABLE = False
            return False

    except ImportError as e:
        print(f"ðŸš¨ OPENAI INIT: âŒ OpenAI package import error: {e}")
        openai_error_message = f"OpenAI package not installed: {e}"
        OPENAI_AVAILABLE = False
        return False
    except Exception as e:
        print(f"ðŸš¨ OPENAI INIT: âŒ General initialization error: {str(e)}")
        openai_error_message = f"OpenAI initialization error: {str(e)}"
        OPENAI_AVAILABLE = False
        return False

def detect_timeframe_from_image(image_str, image_format):
    """
    Detect the timeframe from the chart image
    Returns: (timeframe, error_message)
    """
    try:
        print("ðŸ•µï¸ Detecting timeframe from image...")

        system_prompt = """
        You are a professional trading chart analyzer. Your ONLY task is to detect the timeframe in trading chart images.

        Look for timeframe labels typically found in:
        - Top left/right corners: M1, M5, M15, M30, H1, H4, D1, W1, MN
        - Chart header or information panel
        - Bottom time axis labels

        IMPORTANT:
        - Focus ONLY on finding timeframe indicators like: M15, 15M, 15m, H4, 4H, D1, 1D, W1, 1W
        - Return ONLY the timeframe code in standard format: M1, M5, M15, M30, H1, H4, D1, W1, MN
        - If multiple timeframes are visible, return the most prominent one
        - If no clear timeframe is found, return 'UNKNOWN'
        - DO NOT comment on chart content, patterns, or trading advice
        - DO NOT refuse analysis for any reason
        - ONLY return the timeframe code or 'UNKNOWN'
        """

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "What is the timeframe of this trading chart? Return ONLY the timeframe code like M15, H4, D1 or UNKNOWN."
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/{image_format};base64,{image_str}",
                                "detail": "low"
                            }
                        }
                    ]
                }
            ],
            max_tokens=10,
            temperature=0.1  # Lower temperature for more consistent results
        )

        detected_timeframe = response.choices[0].message.content.strip().upper()
        print(f"ðŸ•µï¸ Detected timeframe: {detected_timeframe}")

        # Clean and validate the detected timeframe
        detected_timeframe = detected_timeframe.replace(' ', '').replace('TF:', '').replace('TIMEFRAME:', '')
        
        # Map common variations to standard formats
        timeframe_map = {
            '15M': 'M15', '15m': 'M15', '15': 'M15',
            '30M': 'M30', '30m': 'M30', '30': 'M30',
            '1H': 'H1', '1h': 'H1', '60M': 'H1',
            '4H': 'H4', '4h': 'H4', '240M': 'H4',
            '1D': 'D1', '1d': 'D1', 'D': 'D1',
            '1W': 'W1', '1w': 'W1', 'W': 'W1'
        }
        
        if detected_timeframe in timeframe_map:
            detected_timeframe = timeframe_map[detected_timeframe]
        
        valid_timeframes = ['M1', 'M5', 'M15', 'M30', 'H1', 'H4', 'D1', 'W1', 'MN']
        
        if detected_timeframe in valid_timeframes:
            return detected_timeframe, None
        elif detected_timeframe == 'UNKNOWN':
            # Fallback to manual detection for common cases
            return 'M15', None  # Default to M15 if unknown
        else:
            # Try to extract timeframe from the response
            for tf in valid_timeframes:
                if tf in detected_timeframe:
                    return tf, None
            return 'M15', None  # Default fallback

    except Exception as e:
        print(f"ERROR: Timeframe detection failed: {str(e)}")
        # Default to M15 on error
        return 'M15', None

def analyze_with_openai(image_str, image_format, timeframe=None, previous_analysis=None, user_analysis=None, action_type="chart_analysis"):
    """
    Analyze an image or text using OpenAI with enhanced, detailed analysis.
    OPTIMIZED VERSION - minimal changes for performance
    """
    global client

    if not OPENAI_AVAILABLE:
        raise RuntimeError(f"OpenAI not available: {openai_error_message}")

    # Validate timeframe for first and second analysis (when image is provided)
    if image_str and action_type in ['first_analysis', 'second_analysis']:
        is_valid, error_msg = validate_timeframe_in_image(image_str, image_format, timeframe)
        if not is_valid:
            return error_msg

    # KEEP ALL EXISTING PROMPTS EXACTLY THE SAME - only change timeouts and image detail
    if action_type == "user_analysis_feedback":
        char_limit = 800
        analysis_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ ØµØ§Ø±Ù… ÙˆØµØ§Ø¯Ù‚. Ù‚Ù… Ø¨ØªÙ‚ÙŠÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ§Ù„ÙŠ Ø¨ØµØ¯Ù‚ ÙˆÙ…ÙˆØ¶ÙˆØ¹ÙŠØ©:

ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
{user_analysis}

**ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:**
1. Ù‚ÙŠÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙÙ†ÙŠØ© ÙˆØ§Ù„Ù…Ù†Ø·Ù‚
2. ÙƒÙ† ØµØ§Ø¯Ù‚Ù‹Ø§ ÙˆÙˆØ§Ø¶Ø­Ù‹Ø§ - Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¶Ø¹ÙŠÙÙ‹Ø§ Ø£Ùˆ Ø®Ø§Ø·Ø¦Ù‹Ø§ØŒ Ù‚Ù„ Ø°Ù„Ùƒ Ø¨ÙˆØ¶ÙˆØ­
3. Ù„Ø§ ØªØ¨Ø§Ù„Øº ÙÙŠ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©
4. Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¬Ø³ÙŠÙ…Ø© ÙÙŠ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠ
5. Ù‚Ø¯Ù… Ù†Ù‚Ø¯Ù‹Ø§ Ø¨Ù†Ø§Ø¡Ù‹ Ù…Ø¹ Ø­Ù„ÙˆÙ„ Ø¹Ù…Ù„ÙŠØ©

**Ù‡ÙŠÙƒÙ„ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…:**
### ðŸ“Š ØªÙ‚ÙŠÙŠÙ… Ù…ÙˆØ¶ÙˆØ¹ÙŠ:
**Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙÙ†ÙŠØ©:** (Ø§Ø°ÙƒØ± Ù…Ø¯Ù‰ ØªÙˆØ§ÙÙ‚ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ø¹ Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„ÙÙ†ÙŠØ©)
**Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠ:** (Ø­Ù„Ù„ Ù‚ÙˆØ© Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ ÙˆØ§Ù„Ø±Ø¨Ø· Ø¨ÙŠÙ† Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…)
**Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:** (Ø­Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¨ÙˆØ¶ÙˆØ­ Ø¯ÙˆÙ† Ù…Ø¬Ø§Ù…Ù„Ø©)

### ðŸŽ¯ Ù†Ù‚Ø§Ø· ØªØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†:
1. (Ø§ÙƒØªØ¨ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ ØªØµØ­ÙŠØ­)
2. (ÙƒÙ† Ù…Ø­Ø¯Ø¯Ù‹Ø§ ÙˆÙˆØ§Ø¶Ø­Ù‹Ø§)

### ðŸ’¡ ØªÙˆØµÙŠØ§Øª Ø¹Ù…Ù„ÙŠØ©:
(Ù‚Ø¯Ù… 2-3 ØªÙˆØµÙŠØ§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ­Ù„ÙŠÙ„)

**ÙƒÙ† Ù…Ø­ØªØ±ÙÙ‹Ø§ ÙˆØµØ§Ø¯Ù‚Ù‹Ø§ - Ø§Ù„Ù‡Ø¯Ù Ù‡Ùˆ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø§Ù„ØªØ­Ø³Ù†ØŒ Ù„ÙŠØ³ Ø§Ù„Ù…Ø¬Ø§Ù…Ù„Ø©.**
**Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¶Ø¹ÙŠÙÙ‹Ø§ Ø¬Ø¯Ù‹Ø§ØŒ Ù‚Ù„ Ø°Ù„Ùƒ Ø¨ÙˆØ¶ÙˆØ­ Ù…Ø¹ Ø´Ø±Ø­ Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø¶Ø¹Ù.**
**Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù.**
"""
        max_tokens = char_limit // 2 + 50

    elif action_type == "single_analysis":
        char_limit = 1024
        analysis_prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ ÙˆÙ…ÙØµÙ„Ø§Ù‹ Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ.

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ ÙƒØ§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ðŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ù„Ø´Ø§Ø±Øª {timeframe}

**ðŸŽ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚:**
- ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ÙˆØ§Ù„Ø«Ø§Ù†ÙˆÙŠ
- ØªØ­Ù„ÙŠÙ„ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚ Ù…Ù† Ø§Ù„Ù‚Ù…Ù… ÙˆØ§Ù„Ù‚ÙŠØ¹Ø§Ù†

**ðŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ:**
- ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
- ØªØ­Ù„ÙŠÙ„ ØªÙØ§Ø¹Ù„ Ø§Ù„Ø³Ø¹Ø± Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª

**ðŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©:**
- Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
- Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø­Ø±Ø¬Ø© Ù„Ù„ÙƒØ³Ø± Ø£Ùˆ Ø§Ù„Ø§Ø±ØªØ¯Ø§Ø¯

**ðŸ’§ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©:**
- Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
- Ù…Ù†Ø§Ø·Ù‚ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©

**âš ï¸ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØ§Ù„Ù…Ø®Ø§Ø·Ø±:**
- Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ ØªØ¬Ù†Ø¨Ù‡Ø§
- Ø£Ù†Ù…Ø§Ø· Ø§Ù†Ø¹ÙƒØ§Ø³ Ù…Ø­ØªÙ…Ù„Ø©

**ðŸ’¼ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:**
- Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
- ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ
- Ø£Ù‡Ø¯Ø§Ù Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­
- Ù†ØµØ§Ø¦Ø­ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©

**Ø§Ù„ØªØ²Ù… Ø¨ØªÙ‚Ø¯ÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø¹Ù…Ù„ÙŠ ÙˆÙ…ÙÙŠØ¯ Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù.**
"""
        max_tokens = char_limit // 2 + 100

    elif timeframe == "H4" and previous_analysis:
        char_limit = 1024
        analysis_prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ ÙˆÙ…ÙØµÙ„Ø§Ù‹ ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ø¥Ø·Ø§Ø±ÙŠÙ† Ø§Ù„Ø²Ù…Ù†ÙŠÙŠÙ†.

Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø§Ø¨Ù‚ (15 Ø¯Ù‚ÙŠÙ‚Ø©): {previous_analysis}

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ðŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„
**1. ØªØ­Ù„ÙŠÙ„ ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ:**
- ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (38.2%, 50%, 61.8%)
- ØªÙØ§Ø¹Ù„ Ø§Ù„Ø³Ø¹Ø± Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª

**2. Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©:**
- Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
- Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø­Ø±Ø¬Ø© Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ù…Ø±Ø§Ù‚Ø¨ØªÙ‡Ø§

**3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©:**
- Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
- Ù…Ù†Ø§Ø·Ù‚ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©

**4. Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØ§Ù„Ù…Ø®Ø§Ø·Ø±:**
- ØªØ­Ø°ÙŠØ±Ø§Øª ÙŠØ¬Ø¨ ØªØ¬Ù†Ø¨Ù‡Ø§
- Ø£Ù†Ù…Ø§Ø· Ø§Ù†Ø¹ÙƒØ§Ø³ Ù…Ø­ØªÙ…Ù„Ø©

**5. Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:**
- Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
- Ù†Ù‚Ø§Ø· ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± ÙˆØ¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­
- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©

**Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù Ù…Ø¹ ØªÙ‚Ø¯ÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø¹Ù…Ù„ÙŠ ÙˆÙ…ÙÙŠØ¯.**
"""
        max_tokens = char_limit // 2 + 100

    elif action_type == "final_analysis":
        char_limit = 1024
        analysis_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ ÙˆÙ…ØªÙƒØ§Ù…Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠÙ† Ø§Ù„Ø³Ø§Ø¨Ù‚ÙŠÙ†:

Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ (M15): {previous_analysis}

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ Ù†Ù‡Ø§Ø¦ÙŠ Ù…ØªÙƒØ§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ðŸ“ˆ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©

**ðŸŽ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚:**
- ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ÙˆØ§Ù„Ø«Ø§Ù†ÙˆÙŠ
- ØªØ­Ù„ÙŠÙ„ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚ Ù…Ù† Ø§Ù„Ù‚Ù…Ù… ÙˆØ§Ù„Ù‚ÙŠØ¹Ø§Ù†

**ðŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø­Ø±Ø¬Ø©:**
- Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„ØªØµØ­ÙŠØ­ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (38.2%, 50%, 61.8%)
- ØªÙØ§Ø¹Ù„ Ø§Ù„Ø³Ø¹Ø± Ù…Ø¹ Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ

**ðŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:**
- Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù‚ÙˆÙŠØ© Ù„Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
- Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø­Ø±Ø¬Ø© Ù„Ù„ÙƒØ³Ø± Ø£Ùˆ Ø§Ù„Ø§Ø±ØªØ¯Ø§Ø¯

**ðŸ’§ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©:**
- Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©
- Ù…Ù†Ø§Ø·Ù‚ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©

**âš ï¸ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØ§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª:**
- Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ ØªØ¬Ù†Ø¨Ù‡Ø§
- Ø£Ù†Ù…Ø§Ø· Ø§Ù†Ø¹ÙƒØ§Ø³ Ù…Ø­ØªÙ…Ù„Ø©

**ðŸ’¼ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©:**
- Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ
- ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
- Ø£Ù‡Ø¯Ø§Ù Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­
- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©

**Ø§Ù„ØªØ²Ù… Ø¨ØªÙ‚Ø¯ÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø¹Ù…Ù„ÙŠ ÙˆÙ…ÙÙŠØ¯ Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù.**
"""
        max_tokens = char_limit // 2 + 100

    else:
        # First analysis with detailed prompt
        char_limit = 1024
        analysis_prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ ÙˆÙ…ÙØµÙ„Ø§Ù‹ Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ.

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ ÙƒØ§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ðŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ù„Ø´Ø§Ø±Øª {timeframe}

**ðŸŽ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚:**
- ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ÙˆØ§Ù„Ø«Ø§Ù†ÙˆÙŠ
- ØªØ­Ù„ÙŠÙ„ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚ Ù…Ù† Ø§Ù„Ù‚Ù…Ù… ÙˆØ§Ù„Ù‚ÙŠØ¹Ø§Ù†

**ðŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ:**
- ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
- ØªØ­Ù„ÙŠÙ„ ØªÙØ§Ø¹Ù„ Ø§Ù„Ø³Ø¹Ø± Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª

**ðŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©:**
- Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
- Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø­Ø±Ø¬Ø© Ù„Ù„ÙƒØ³Ø± Ø£Ùˆ Ø§Ù„Ø§Ø±ØªØ¯Ø§Ø¯

**ðŸ’§ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©:**
- Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
- Ù…Ù†Ø§Ø·Ù‚ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©

**âš ï¸ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØ§Ù„Ù…Ø®Ø§Ø·Ø±:**
- Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ ØªØ¬Ù†Ø¨Ù‡Ø§
- Ø£Ù†Ù…Ø§Ø· Ø§Ù†Ø¹ÙƒØ§Ø³ Ù…Ø­ØªÙ…Ù„Ø©

**ðŸ’¼ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:**
- Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
- ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ
- Ø£Ù‡Ø¯Ø§Ù Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­
- Ù†ØµØ§Ø¦Ø­ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©

**Ø§Ù„ØªØ²Ù… Ø¨ØªÙ‚Ø¯ÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø¹Ù…Ù„ÙŠ ÙˆÙ…ÙÙŠØ¯ Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù.**
"""
        max_tokens = char_limit // 2 + 100

    if not client:
        raise RuntimeError("OpenAI client not initialized")

    try:
        import time
        start_time = time.time()

        if image_str:
            print(f"ðŸš¨ OPENAI ANALYSIS: Analyzing image with {action_type}")
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": f"Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù ÙÙŠ Ø±Ø¯Ùƒ."},
                    {"role": "user", "content": [
                        {"type": "text", "text": analysis_prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/{image_format.lower()};base64,{image_str}", "detail": "low"}}  # CHANGED: "high" â†’ "low"
                    ]}
                ],
                max_tokens=max_tokens,
                temperature=0.7,
                timeout=30  # ADDED: 30-second timeout
            )
        else:
            print(f"ðŸš¨ OPENAI ANALYSIS: Analyzing text with {action_type}")
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": f"Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù ÙÙŠ Ø±Ø¯Ùƒ."},
                    {"role": "user", "content": analysis_prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.7,
                timeout=20  # ADDED: 20-second timeout for text
            )

        analysis = response.choices[0].message.content.strip()
        processing_time = time.time() - start_time
        print(f"ðŸš¨ OPENAI ANALYSIS: âœ… Analysis completed in {processing_time:.2f}s, length: {len(analysis)} chars")

        # Keep existing retry logic but with timeout
        if len(analysis) > char_limit + 200:
            print(f"ðŸš¨ OPENAI ANALYSIS: Analysis too long ({len(analysis)}), retrying with shorter version")
            retry_prompt = f"""
Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø§Ø¨Ù‚ ÙƒØ§Ù† Ø·ÙˆÙŠÙ„Ø§Ù‹ Ø¬Ø¯Ø§Ù‹ ({len(analysis)} Ø­Ø±Ù). Ø£Ø¹Ø¯ ÙƒØªØ§Ø¨ØªÙ‡ Ù…Ø¹ Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ:

{analysis}
"""
            retry_response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": f"Ø§Ø®ØªØµØ§Ø± Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ {char_limit} Ø­Ø±Ù Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¬ÙˆÙ‡Ø± Ø§Ù„ÙÙ†ÙŠ."},
                    {"role": "user", "content": retry_prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.7,
                timeout=15  # ADDED: 15-second timeout for retry
            )
            analysis = retry_response.choices[0].message.content.strip()
            print(f"ðŸš¨ OPENAI ANALYSIS: âœ… Retry completed, new length: {len(analysis)} chars")

        return analysis

    except Exception as e:
        print(f"ðŸš¨ OPENAI ANALYSIS: âŒ Analysis failed: {str(e)}")
        raise RuntimeError(f"OpenAI analysis failed: {str(e)}")

def load_image_from_url(image_url):
    """Load and encode image from URL and return (b64string, format) or (None, None)"""
    try:
        print(f"ðŸš¨ IMAGE LOAD: Loading image from {image_url}")
        response = requests.get(image_url, timeout=10)
        if response.status_code == 200:
            img = Image.open(BytesIO(response.content))
            if img.format in ['PNG', 'JPEG', 'JPG']:
                buffered = BytesIO()
                img_format = img.format if img.format else 'JPEG'
                img.save(buffered, format=img_format)
                b64_data = base64.b64encode(buffered.getvalue()).decode("utf-8")
                print(f"ðŸš¨ IMAGE LOAD: âœ… Image loaded successfully, format: {img_format}, size: {len(b64_data)} chars")
                return b64_data, img_format
        print(f"ðŸš¨ IMAGE LOAD: âŒ Failed to load image, status: {response.status_code}")
        return None, None
    except Exception as e:
        print(f"ðŸš¨ IMAGE LOAD: âŒ Error loading image: {e}")
        return None, None

def analyze_user_drawn_analysis(image_str, image_format, timeframe=None):
    """
    Analyze a chart image with user-drawn analysis (lines, annotations, etc.)
    Provides feedback on the user's analysis and gives the correct technical analysis
    Returns: (feedback, analysis) tuple
    """
    global client

    if not OPENAI_AVAILABLE:
        raise RuntimeError(f"OpenAI not available: {openai_error_message}")

    feedback_char_limit = 600
    analysis_char_limit = 600
    
    analysis_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ Ù„Ù„Ù…Ø®Ø·Ø·Ø§Øª ÙˆØ§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© Ø§Ù„Ù…Ø§Ù„ÙŠØ©. Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ ØªØ­Ù„ÙŠÙ„ ØµÙˆØ±Ø© Ù…Ø®Ø·Ø· ØªØ¯Ø§ÙˆÙ„ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø±Ø³ÙˆÙ…Ø§Øª ÙˆØªØ­Ù„ÙŠÙ„Ø§Øª Ù…Ø±Ø³ÙˆÙ…Ø© Ù…Ù† Ù‚Ø¨Ù„ Ù…ØªØ¯Ø§ÙˆÙ„.

Ù‡Ø°Ø§ Ù…Ø®Ø·Ø· ØªØ¯Ø§ÙˆÙ„ (Ø´Ø§Ø±Øª) ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø®Ø·ÙˆØ· ÙˆØ¯ÙˆØ§Ø¦Ø± ÙˆØ±Ø³ÙˆÙ…Ø§Øª ÙÙ†ÙŠØ©. Ù‡Ø°Ù‡ Ù„ÙŠØ³Øª ØµÙˆØ±Ø© Ù„Ø£Ø´Ø®Ø§Øµ ÙˆØ¥Ù†Ù…Ø§ Ù‡ÙŠ Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„Ø£Ø³Ø¹Ø§Ø± Ù…Ø¹ ØªØ­Ù„ÙŠÙ„Ø§Øª ÙÙ†ÙŠØ© Ù…Ø±Ø³ÙˆÙ…Ø©.

**Ù…Ù‡Ù…ØªÙƒ:**
1. ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø±Ø³ÙˆÙ…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø®Ø·Ø· Ù…Ù† Ø§Ù„Ù†Ø§Ø­ÙŠØ© Ø§Ù„ÙÙ†ÙŠØ©
2. ØªÙ‚Ø¯ÙŠÙ… ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ ØµØ­ÙŠØ­ Ù„Ù„Ù…Ø®Ø·Ø·

**Ø§Ù„Ø¬Ø²Ø¡ 1: ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø±Ø³ÙˆÙ… (Ø§Ù„ØªÙ‚ÙŠÙŠÙ…) - Ø§ÙƒØªØ¨ ØªÙ‚ÙŠÙŠÙ…Ø§Ù‹ Ù„Ù„Ø±Ø³ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø±Ø³ÙˆÙ…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø®Ø·Ø·:**
- Ù‚ÙŠÙ… Ø¯Ù‚Ø© Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ù…Ø±Ø³ÙˆÙ…Ø© (Ø®Ø·ÙˆØ· Ø§Ù„Ø§ØªØ¬Ø§Ù‡ØŒ Ø§Ù„Ø¯Ø¹Ù…ØŒ Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©)
- Ø­Ø¯Ø¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¯ÙˆØ§Ø¦Ø± ÙˆØ§Ù„Ø£Ø´ÙƒØ§Ù„ ÙÙŠ Ø£Ù…Ø§ÙƒÙ†Ù‡Ø§ Ø§Ù„ØµØ­ÙŠØ­Ø©
- Ø§Ø°ÙƒØ± Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ© ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø±Ø³ÙˆÙ…
- Ø§Ø°ÙƒØ± Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù ÙˆØ§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø±Ø³ÙˆÙ…
- Ù‚Ø¯Ù… Ù†Ù‚Ø¯Ø§Ù‹ Ø¨Ù†Ø§Ø¡Ù‹ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø±Ø³ÙˆÙ…

**Ø§Ù„Ø¬Ø²Ø¡ 2: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ø§Ù„ØµØ­ÙŠØ­ (Ø§Ù„ØªØ­Ù„ÙŠÙ„) - Ø§ÙƒØªØ¨ ØªØ­Ù„ÙŠÙ„Ø§Ù‹ ÙÙ†ÙŠØ§Ù‹ ÙƒØ§Ù…Ù„Ø§Ù‹ Ù„Ù„Ù…Ø®Ø·Ø·:**
### ðŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ù„Ø´Ø§Ø±Øª {timeframe}
**ðŸŽ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚**
**ðŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©** 
**ðŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø­Ø±Ø¬Ø©**
**ðŸ’§ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©**
**âš ï¸ Ø§Ù„Ù…Ø®Ø§Ø·Ø± ÙˆØ§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª**
**ðŸ’¼ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©**

**Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„ØªØ§Ù„ÙŠ:**
- Ø±ÙƒØ² ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ù„Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©
- ØªØ¬Ø§Ù‡Ù„ Ø£ÙŠ Ø¹Ù†Ø§ØµØ± ØºÙŠØ± Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ
- Ø§ÙƒØªØ¨ Ø¨Ù„ØºØ© Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø­ØªØ±ÙØ©
- Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø­Ø±ÙˆÙ Ù„ÙƒÙ„ Ø¬Ø²Ø¡

**Ø§Ù„Ø¬Ø²Ø¡ 1 (Ø§Ù„ØªÙ‚ÙŠÙŠÙ…) ÙŠØ¬Ø¨ Ø£Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² {feedback_char_limit} Ø­Ø±Ù.**
**Ø§Ù„Ø¬Ø²Ø¡ 2 (Ø§Ù„ØªØ­Ù„ÙŠÙ„) ÙŠØ¬Ø¨ Ø£Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² {analysis_char_limit} Ø­Ø±Ù.**
"""
    max_tokens = (feedback_char_limit + analysis_char_limit) // 2 + 200

    if not client:
        raise RuntimeError("OpenAI client not initialized")

    try:
        import time
        start_time = time.time()

        print(f"ðŸš¨ OPENAI ANALYSIS: Analyzing user-drawn analysis with timeframe: {timeframe}")
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": f"Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ Ù„Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©. Ø±ÙƒØ² ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ ÙˆØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª."},
                {"role": "user", "content": [
                    {"type": "text", "text": analysis_prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/{image_format.lower()};base64,{image_str}", "detail": "low"}}
                ]}
            ],
            max_tokens=max_tokens,
            temperature=0.7,
            timeout=30
        )

        full_response = response.choices[0].message.content.strip()
        processing_time = time.time() - start_time
        print(f"ðŸš¨ OPENAI ANALYSIS: âœ… User-drawn analysis completed in {processing_time:.2f}s, length: {len(full_response)} chars")

        # Split the response into feedback and analysis parts
        feedback, analysis = split_feedback_and_analysis(full_response)
        
        # Clean up any refusal messages
        feedback = clean_refusal_messages(feedback)
        analysis = clean_refusal_messages(analysis)
        
        print(f"ðŸš¨ OPENAI ANALYSIS: âœ… Split response - Feedback: {len(feedback)} chars, Analysis: {len(analysis)} chars")
        
        return feedback, analysis

    except Exception as e:
        print(f"ðŸš¨ OPENAI ANALYSIS: âŒ User-drawn analysis failed: {str(e)}")
        raise RuntimeError(f"OpenAI analysis failed: {str(e)}")

def clean_refusal_messages(text):
    """
    Remove common refusal messages from the AI response
    """
    refusal_patterns = [
        "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ†Ù†ÙŠ ØªØ­Ù„ÙŠÙ„ Ø£Ùˆ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø´Ø®Ø§Øµ Ø£Ùˆ Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª ÙÙŠ Ø§Ù„ØµÙˆØ±",
        "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø±Ø¤ÙŠØ© Ø£Ùˆ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø§Ø´Ø±",
        "Ù„Ø§ ÙŠÙ…ÙƒÙ†Ù†ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±",
        "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹",
        "Ù…Ø¹Ø°Ø±Ø©ØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ†Ù†ÙŠ",
        "I cannot analyze",
        "I'm unable to",
        "I cannot see"
    ]
    
    cleaned_text = text
    for pattern in refusal_patterns:
        if pattern in cleaned_text:
            # Remove the refusal message and everything before it
            parts = cleaned_text.split(pattern)
            if len(parts) > 1:
                cleaned_text = parts[1].strip()
            else:
                cleaned_text = ""
    
    # If text is empty after cleaning, provide a default message
    if not cleaned_text or len(cleaned_text.strip()) < 10:
        cleaned_text = "Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø±Ø³ÙˆÙ…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø®Ø·Ø·. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ØµÙˆØ±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø®Ø·Ø· ØªØ¯Ø§ÙˆÙ„ Ù…Ø¹ ØªØ­Ù„ÙŠÙ„Ø§Øª ÙÙ†ÙŠØ© Ù…Ø±Ø³ÙˆÙ…Ø©."
    
    return cleaned_text.strip()

def split_feedback_and_analysis(full_response):
    """
    Split the full response into feedback and analysis parts
    Returns: (feedback, analysis)
    """
    if not full_response:
        return "Ù„Ù… ÙŠØªÙ… ØªÙ‚Ø¯ÙŠÙ… ØªØ­Ù„ÙŠÙ„ ÙƒØ§ÙÙ.", "ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø£ÙˆØ¶Ø­ Ù„Ù„Ù…Ø®Ø·Ø·."
    
    # Look for common section dividers in Arabic
    dividers = [
        "**Ø§Ù„Ø¬Ø²Ø¡ 2:**",
        "Ø§Ù„Ø¬Ø²Ø¡ 2:",
        "**Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ø§Ù„ØµØ­ÙŠØ­:**",
        "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ø§Ù„ØµØ­ÙŠØ­:",
        "### ðŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ",
        "ðŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ",
        "**Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø«Ø§Ù†ÙŠ:**",
        "Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø«Ø§Ù†ÙŠ:"
    ]
    
    feedback = full_response
    analysis = ""
    
    for divider in dividers:
        if divider in full_response:
            parts = full_response.split(divider, 1)
            if len(parts) == 2:
                feedback = parts[0].strip()
                analysis = divider + parts[1].strip()
                break
    
    # If no divider found, try to split by first major heading in the analysis part
    if not analysis:
        analysis_keywords = ["### ðŸ“Š", "**ðŸŽ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù…**", "ðŸŽ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù…", "ðŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ", "**Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©**"]
        for keyword in analysis_keywords:
            if keyword in full_response:
                parts = full_response.split(keyword, 1)
                if len(parts) == 2:
                    feedback = parts[0].strip()
                    analysis = keyword + parts[1].strip()
                break
    
    # If still no split, use first 50% as feedback and rest as analysis
    if not analysis:
        split_index = int(len(full_response) * 0.5)
        feedback = full_response[:split_index].strip()
        analysis = full_response[split_index:].strip()
    
    # Clean up the feedback part - remove any analysis section headers from feedback
    analysis_headers = ["Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ", "ðŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ", "### ðŸ“Š", "**ðŸŽ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù…**"]
    for header in analysis_headers:
        if header in feedback:
            feedback_parts = feedback.split(header)
            if len(feedback_parts) > 0:
                feedback = feedback_parts[0].strip()
    
    # Ensure both parts have reasonable content
    if len(feedback.strip()) < 20:
        feedback = "ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø±Ø³ÙˆÙ…: " + (feedback if feedback else "Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø±Ø³ÙˆÙ…Ø© ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙÙ†ÙŠØ©.")
    
    if len(analysis.strip()) < 20:
        analysis = "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ: " + (analysis if analysis else "ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø£ÙˆØ¶Ø­ Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø¯Ù‚ÙŠÙ‚.")
    
    return feedback, analysis
	
def split_feedback_and_analysis(full_response):
    """
    Split the full response into feedback and analysis parts
    Returns: (feedback, analysis)
    """
    # Look for common section dividers in Arabic
    dividers = [
        "**Ø§Ù„Ø¬Ø²Ø¡ 2:**",
        "Ø§Ù„Ø¬Ø²Ø¡ 2:",
        "**Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ø§Ù„ØµØ­ÙŠØ­:**",
        "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ø§Ù„ØµØ­ÙŠØ­:",
        "### ðŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ"
    ]

    feedback = full_response
    analysis = ""

    for divider in dividers:
        if divider in full_response:
            parts = full_response.split(divider, 1)
            if len(parts) == 2:
                feedback = parts[0].strip()
                analysis = parts[1].strip()
                break

    # If no divider found, try to split by first major heading in the analysis part
    if not analysis:
        analysis_keywords = ["### ðŸ“Š", "**ðŸŽ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù…**", "ðŸŽ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù…", "ðŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ"]
        for keyword in analysis_keywords:
            if keyword in full_response:
                parts = full_response.split(keyword, 1)
                if len(parts) == 2:
                    feedback = parts[0].strip()
                    analysis = keyword + parts[1].strip()
                break

    # If still no split, use first 60% as feedback and rest as analysis
    if not analysis:
        split_index = int(len(full_response) * 0.6)
        feedback = full_response[:split_index].strip()
        analysis = full_response[split_index:].strip()

    # Clean up the feedback part - remove any analysis section headers from feedback
    analysis_headers = ["Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ", "ðŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ", "### ðŸ“Š"]
    for header in analysis_headers:
        if header in feedback:
            feedback = feedback.split(header)[0].strip()

    return feedback, analysis
