import time
import base64
import requests
import os
import re
from PIL import Image
from io import BytesIO
from config import Config

OPENAI_AVAILABLE = False
client = None
openai_error_message = ""
openai_last_check = 0

def log_openai_response(action_type, response_content, char_limit=1024):
    """
    Comprehensive logging for OpenAI responses
    """
    print(f"\n{'='*80}")
    print(f"ğŸš¨ OPENAI RESPONSE LOG - {action_type.upper()}")
    print(f"{'='*80}")
    print(f"ğŸ“Š Response length: {len(response_content)} characters")
    print(f"ğŸ“ Character limit: {char_limit}")
    print(f"ğŸ“ˆ Limit exceeded: {len(response_content) > char_limit}")
    print(f"ğŸ“‹ Full response content:")
    print(f"{'='*40}")
    print(response_content)
    print(f"{'='*40}")
    print(f"ğŸ” Response ends with: ...{response_content[-50:] if len(response_content) > 50 else response_content}")
    print(f"{'='*80}\n")

def check_recommendations(action_type, analysis_text):
    """
    Check if the analysis contains essential recommendations
    """
    print(f"\nğŸ” RECOMMENDATION CHECK - {action_type.upper()}")

    # Keywords to check for in Arabic and English
    recommendation_keywords = [
        'ØªÙˆØµÙŠØ©', 'ØªÙˆØµÙŠØ§Øª', 'Ø¯Ø®ÙˆÙ„', 'Ø´Ø±Ø§Ø¡', 'Ø¨ÙŠØ¹', 'Ù‡Ø¯Ù', 'Ø£Ù‡Ø¯Ø§Ù',
        'recommendation', 'entry', 'buy', 'sell', 'target', 'stop loss'
    ]

    timeframe_keywords = [
        '15 Ø¯Ù‚ÙŠÙ‚Ø©', 'Ø±Ø¨Ø¹ Ø³Ø§Ø¹Ø©', 'Ø®Ù…Ø³Ø© Ø¹Ø´Ø±', 'Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©', 'Ø§Ù„Ù…Ù‚Ø¨Ù„Ø©',
        '15 minute', 'next 15', 'quarter', 'coming'
    ]

    has_recommendation = any(keyword in analysis_text.lower() for keyword in recommendation_keywords)
    has_timeframe = any(keyword in analysis_text.lower() for keyword in timeframe_keywords)

    print(f"ğŸ“Š Has recommendations: {has_recommendation}")
    print(f"â° Has timeframe mention: {has_timeframe}")
    print(f"ğŸ“ Recommendation check passed: {has_recommendation and has_timeframe}")

    if not has_recommendation:
        print("âš ï¸ WARNING: Analysis missing trading recommendations!")
    if not has_timeframe:
        print("âš ï¸ WARNING: Analysis missing 15-minute timeframe context!")

def shorten_analysis_text(analysis_text, char_limit=1024, timeframe=None, currency=None):
    """
    CONSERVATIVE shortening that preserves ALL critical trading information in ARABIC
    Targets 980-1024 characters range while keeping essential data
    """
    global client
    
    if len(analysis_text) <= char_limit:
        return analysis_text

    print(f"ğŸ“ CONSERVATIVE SHORTENING: Analysis slightly long ({len(analysis_text)} chars), optimizing...")

    try:
        # CONSERVATIVE PROMPT - Only remove non-essential parts
        shortening_prompt = f"""
        Ù…Ù‡Ù…ØªÙƒ: ØªÙ‚ØµÙŠØ± ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„ØªØ§Ù„ÙŠ Ù‚Ù„ÙŠÙ„Ø§Ù‹ ÙÙ‚Ø· Ù„ÙŠØµØ¨Ø­ Ø¨ÙŠÙ† 980 Ùˆ 1024 Ø­Ø±Ù Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©.

        **Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„ÙŠÙ‡Ø§ ÙƒØ§Ù…Ù„Ø© Ø¨Ø¯ÙˆÙ† Ø­Ø°Ù:**
        1. Ø¬Ù…ÙŠØ¹ ØªÙˆØµÙŠØ§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„ (Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯Ø®ÙˆÙ„ØŒ Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø´Ø±Ø§Ø¡/Ø§Ù„Ø¨ÙŠØ¹)
        2. Ù…Ø³ØªÙˆÙŠØ§Øª ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨Ø§Ù„Ø¶Ø¨Ø· (Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø±Ù‚Ù…ÙŠØ©)
        3. Ø£Ù‡Ø¯Ø§Ù Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­ Ø¨Ø§Ù„Ø¶Ø¨Ø· (Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø±Ù‚Ù…ÙŠØ©) 
        4. Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø§Ø¦Ø¯
        5. Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        6. Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© ÙˆØ£ÙˆØ§Ù…Ø± Ø§Ù„ØªØ¬Ù…ÙŠØ¹
        7. Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ù‚ÙŠÙ… ÙˆØ§Ù„Ø­Ø³Ø§Ø¨Ø§Øª

        **Ù…Ø§ ÙŠÙ…ÙƒÙ† ØªÙ‚Ù„ÙŠÙ„Ù‡ ÙÙ‚Ø· (Ù„Ø§ ØªØ­Ø°Ù):**
        - ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø´Ø±ÙˆØ­ Ø§Ù„ÙÙ†ÙŠØ© Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© Ø¹Ù† Ø§Ù„Ø­Ø§Ø¬Ø©
        - ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªÙƒØ±Ø§Ø± ÙÙŠ Ø§Ù„ÙˆØµÙ
        - Ø¯Ù…Ø¬ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø·ÙˆÙŠÙ„Ø© ÙÙŠ Ø¬Ù…Ù„ Ù…Ø®ØªØµØ±Ø©
        - ØªÙ‚Ù„ÙŠÙ„ Ø£Ø­Ø±Ù Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© (===, ---, ***) Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø¸ÙŠÙ…

        **Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹:**
        - Ø­Ø°Ù Ø£ÙŠ ØªÙˆØµÙŠØ© ØªØ¯Ø§ÙˆÙ„
        - Ø­Ø°Ù Ø£ÙŠ Ø±Ù‚Ù… Ø£Ùˆ Ù‚ÙŠÙ…Ø©
        - Ø­Ø°Ù ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø£Ùˆ Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­
        - Ø­Ø°Ù Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø§Ø¦Ø¯
        - Ø­Ø°Ù Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©

        **Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:**
        - Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        - Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        - Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ù‚ÙŠÙ…
        - Ø§Ù„Ù‡Ø¯Ù: 980-1024 Ø­Ø±Ù

        **Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø³ÙŠØ§Ù‚:**
        - Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ: {timeframe if timeframe else 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'}
        - Ø§Ù„Ø¹Ù…Ù„Ø©: {currency if currency else 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯Ø©'}

        Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ØµÙ„ÙŠ ({len(analysis_text)} Ø­Ø±Ù):
        {analysis_text}
        """

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system", 
                    "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù„ØªÙ‚ØµÙŠØ± Ù†ØµÙˆØµ ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„. Ù…Ù‡Ù…ØªÙƒ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª ÙˆØªÙ‚ØµÙŠØ± Ø§Ù„Ù†Øµ Ù‚Ù„ÙŠÙ„Ø§Ù‹ ÙÙ‚Ø· Ù„ÙŠØµØ¨Ø­ Ø¨ÙŠÙ† 980-1024 Ø­Ø±Ù. Ù„Ø§ ØªØ­Ø°Ù Ø£ÙŠ Ø£Ø±Ù‚Ø§Ù… Ø£Ùˆ ØªÙˆØµÙŠØ§Øª."
                },
                {
                    "role": "user",
                    "content": shortening_prompt
                }
            ],
            max_tokens=800,  # Increased to allow for better processing
            temperature=0.1
        )

        shortened = response.choices[0].message.content.strip()
        
        print(f"ğŸ“ CONSERVATIVE SHORTENING: Original: {len(analysis_text)} chars -> Shortened: {len(shortened)} chars")
        
        # Enhanced validation to ensure we didn't lose critical information
        critical_keywords = [
            'ØªÙˆØµÙŠØ©', 'Ø¯Ø®ÙˆÙ„', 'Ø´Ø±Ø§Ø¡', 'Ø¨ÙŠØ¹', 'ÙˆÙ‚Ù', 'Ù‡Ø¯Ù', 'Ù†Ø³Ø¨Ø©', 'Ù…Ø®Ø§Ø·Ø±Ø©', 'Ø¹Ø§Ø¦Ø¯',
            'Ø¯Ø¹Ù…', 'Ù…Ù‚Ø§ÙˆÙ…Ø©', 'Ø³ÙŠÙˆÙ„Ø©', 'Ù†Ù‚Ø·Ø©', 'Ù†Ù‚Ø§Ø·', 'Ø´Ø±Ø·', 'Ø´Ø±Ø· Ø§Ù„Ø¯Ø®ÙˆÙ„'
        ]
        
        missing_critical = [kw for kw in critical_keywords if kw in analysis_text and kw not in shortened]
        if missing_critical:
            print(f"ğŸ“ CONSERVATIVE SHORTENING: âš ï¸ Critical information lost: {missing_critical}")
            # Fall back to smart truncation that preserves recommendations
            return smart_conservative_truncation(analysis_text, char_limit, timeframe, currency)
        
        # If still too long after conservative shortening, use smart truncation
        if len(shortened) > char_limit:
            print(f"ğŸ“ CONSERVATIVE SHORTENING: âš ï¸ Still too long ({len(shortened)} chars), using smart truncation")
            return smart_conservative_truncation(analysis_text, char_limit, timeframe, currency)
        
        # If too short, we might have been too aggressive
        if len(shortened) < 900:
            print(f"ğŸ“ CONSERVATIVE SHORTENING: âš ï¸ Too short ({len(shortened)} chars), might have lost information")
            # Check if we can add back some context without exceeding limit
            additional_context = extract_critical_sections(analysis_text, 150)  # Get 150 chars of critical context
            if additional_context and len(shortened + "\n" + additional_context) <= char_limit:
                shortened += "\n" + additional_context
                print(f"ğŸ“ CONSERVATIVE SHORTENING: âœ… Added back context: {len(shortened)} chars")
        
        print(f"ğŸ“ CONSERVATIVE SHORTENING: âœ… Final optimized length: {len(shortened)} chars")
        return shortened

    except Exception as e:
        print(f"ğŸ“ CONSERVATIVE SHORTENING: âŒ Error shortening analysis: {str(e)}")
        # Use enhanced conservative truncation as fallback
        return smart_conservative_truncation(analysis_text, char_limit, timeframe, currency)

def smart_conservative_truncation(analysis_text, char_limit=1024, timeframe=None, currency=None):
    """
    Smart truncation that preserves the most critical parts of the analysis
    """
    print(f"ğŸ“ SMART TRUNCATION: Using intelligent preservation for {len(analysis_text)} chars")
    
    # Try to find and preserve these critical sections in order of importance
    critical_sections = []
    
    # 1. Look for recommendations section (most important)
    recommendation_keywords = ['ØªÙˆØµÙŠØ©', 'ØªÙˆØµÙŠØ§Øª', 'Ø¯Ø®ÙˆÙ„', 'Ø´Ø±Ø§Ø¡', 'Ø¨ÙŠØ¹', 'Ø§Ù„Ø±Ø¨Ø­', 'Ø§Ù„Ø®Ø³Ø§Ø±Ø©', 'Ù†Ù‚Ø·Ø© Ø¯Ø®ÙˆÙ„']
    rec_start = -1
    for keyword in recommendation_keywords:
        idx = analysis_text.find(keyword)
        if idx != -1 and (rec_start == -1 or idx < rec_start):
            rec_start = idx
    
    if rec_start != -1:
        # Take from recommendation start to end, but limit to reasonable length
        recommendations_section = analysis_text[rec_start:]
        if len(recommendations_section) > 600:  # If too long, take first 600 chars of recommendations
            recommendations_section = recommendations_section[:600]
        critical_sections.append(("ØªÙˆØµÙŠØ§Øª", recommendations_section))
    
    # 2. Look for stop loss and take profit
    sl_tp_keywords = ['ÙˆÙ‚Ù', 'Ù‡Ø¯Ù', 'stop loss', 'take profit', 'Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­']
    sl_tp_sections = []
    for keyword in sl_tp_keywords:
        idx = analysis_text.find(keyword)
        if idx != -1:
            # Take some context around the keyword
            start = max(0, idx - 50)
            end = min(len(analysis_text), idx + 150)
            section = analysis_text[start:end]
            sl_tp_sections.append(section)
    
    if sl_tp_sections:
        critical_sections.append(("ÙˆÙ‚Ù ÙˆÙ‡Ø¯Ù", " ".join(sl_tp_sections)))
    
    # 3. Look for risk-reward ratio
    risk_keywords = ['Ù†Ø³Ø¨Ø©', 'Ù…Ø®Ø§Ø·Ø±Ø©', 'Ø¹Ø§Ø¦Ø¯', 'risk', 'reward']
    risk_sections = []
    for keyword in risk_keywords:
        idx = analysis_text.find(keyword)
        if idx != -1:
            start = max(0, idx - 30)
            end = min(len(analysis_text), idx + 100)
            section = analysis_text[start:end]
            risk_sections.append(section)
    
    if risk_sections:
        critical_sections.append(("Ù…Ø®Ø§Ø·Ø±Ø© ÙˆØ¹Ø§Ø¦Ø¯", " ".join(risk_sections)))
    
    # 4. Get the beginning for context (first 200 chars)
    beginning = analysis_text[:200]
    critical_sections.append(("Ù…Ù‚Ø¯Ù…Ø©", beginning))
    
    # Build the truncated text
    truncated_parts = []
    current_length = 0
    
    # Add timeframe and currency info first
    header = ""
    if timeframe:
        header += f"ğŸ“Š Ø§Ù„Ø¥Ø·Ø§Ø±: {timeframe}"
    if currency and currency != 'UNKNOWN':
        if header:
            header += " | "
        header += f"Ø§Ù„Ø¹Ù…Ù„Ø©: {currency}"
    if header:
        header += "\n\n"
        current_length += len(header)
        truncated_parts.append(header)
    
    # Add critical sections in order of importance
    for section_name, section_text in critical_sections:
        if current_length + len(section_text) + 10 <= char_limit:  # +10 for separators
            truncated_parts.append(section_text)
            current_length += len(section_text) + 2  # +2 for newlines
        else:
            # If we're running out of space, truncate this section
            space_left = char_limit - current_length - 10
            if space_left > 50:  # Only add if we have meaningful space
                truncated_parts.append(section_text[:space_left] + "...")
                current_length += space_left + 3
            break
    
    # If we still have space, add a connector
    if current_length < char_limit - 20 and rec_start > 200:
        connector = "\n[...]\n"
        current_length += len(connector)
        truncated_parts.insert(1, connector)  # Insert after header
    
    final_text = "".join(truncated_parts)
    
    # Final cleanup - ensure we're within limits
    if len(final_text) > char_limit:
        final_text = final_text[:char_limit-3] + "..."
    
    print(f"ğŸ“ SMART TRUNCATION: âœ… Final length: {len(final_text)} chars")
    return final_text

def extract_critical_sections(analysis_text, max_chars=200):
    """
    Extract the most critical sections from analysis for context preservation
    """
    critical_parts = []
    
    # Look for key sections
    key_phrases = [
        'ØªÙˆØµÙŠØ©', 'Ø¯Ø®ÙˆÙ„ Ø¹Ù†Ø¯', 'Ø´Ø±Ø§Ø¡ Ø¹Ù†Ø¯', 'Ø¨ÙŠØ¹ Ø¹Ù†Ø¯', 
        'ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©', 'Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­', 'Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©',
        'Ø§Ù„Ø¯Ø¹Ù… Ø¹Ù†Ø¯', 'Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø¹Ù†Ø¯'
    ]
    
    for phrase in key_phrases:
        idx = analysis_text.find(phrase)
        if idx != -1:
            # Extract context around the phrase
            start = max(0, idx - 20)
            end = min(len(analysis_text), idx + 80)
            section = analysis_text[start:end]
            critical_parts.append(section)
    
    # Combine and limit length
    if critical_parts:
        combined = " | ".join(critical_parts)
        if len(combined) > max_chars:
            combined = combined[:max_chars-3] + "..."
        return combined
    
    return None

def init_openai():
    """
    Initialize OpenAI client and test model availability.
    Sets OPENAI_AVAILABLE, client, openai_error_message, openai_last_check.
    """
    global OPENAI_AVAILABLE, client, openai_error_message, openai_last_check

    print("ğŸš¨ OPENAI INIT: Starting OpenAI initialization...")

    try:
        from openai import OpenAI
        print("ğŸš¨ OPENAI INIT: OpenAI package imported successfully")

        # Get API key from Config
        api_key = Config.OPENAI_API_KEY
        print(f"ğŸš¨ OPENAI INIT: Config.OPENAI_API_KEY = {api_key[:20]}..." if api_key else "ğŸš¨ OPENAI INIT: Config.OPENAI_API_KEY = None")
        print(f"ğŸš¨ OPENAI INIT: API Key exists: {bool(api_key)}")
        print(f"ğŸš¨ OPENAI INIT: API Key length: {len(api_key) if api_key else 0}")

        if not api_key or api_key == "your-api-key-here":
            openai_error_message = "OpenAI API key not configured"
            print(f"ğŸš¨ OPENAI INIT: âŒ API key check failed - not configured or still default")
            OPENAI_AVAILABLE = False
            return False

        print("ğŸš¨ OPENAI INIT: Creating OpenAI client...")
        client = OpenAI(api_key=api_key)
        print("ğŸš¨ OPENAI INIT: OpenAI client created successfully")

        try:
            print("ğŸš¨ OPENAI INIT: Testing model availability...")
            models = client.models.list()
            model_ids = [m.id for m in models.data]
            print(f"ğŸš¨ OPENAI INIT: Found {len(model_ids)} models")
            print(f"ğŸš¨ OPENAI INIT: First few models: {model_ids[:5]}")

            if "gpt-4o" not in model_ids:
                openai_error_message = "GPT-4o model not available in your account"
                print(f"ğŸš¨ OPENAI INIT: âŒ GPT-4o not found in available models")
                OPENAI_AVAILABLE = False
                return False

            print("ğŸš¨ OPENAI INIT: âœ… GPT-4o model found!")
            OPENAI_AVAILABLE = True
            openai_error_message = ""
            openai_last_check = time.time()
            print("ğŸš¨ OPENAI INIT: âœ… OpenAI initialized successfully!")
            return True

        except Exception as e:
            error_msg = str(e)
            print(f"ğŸš¨ OPENAI INIT: âŒ Model list error: {error_msg}")
            if "insufficient_quota" in error_msg:
                openai_error_message = "Account has no API credits. Please add funds to your OpenAI API account."
            elif "invalid_api_key" in error_msg:
                openai_error_message = "Invalid API key. Please check your OPENAI_API_KEY environment variable."
            elif "rate limit" in error_msg.lower():
                openai_error_message = "Rate limit exceeded. Please try again later."
            else:
                openai_error_message = f"OpenAI API test failed: {error_msg}"
            OPENAI_AVAILABLE = False
            return False

    except ImportError as e:
        print(f"ğŸš¨ OPENAI INIT: âŒ OpenAI package import error: {e}")
        openai_error_message = f"OpenAI package not installed: {e}"
        OPENAI_AVAILABLE = False
        return False
    except Exception as e:
        print(f"ğŸš¨ OPENAI INIT: âŒ General initialization error: {str(e)}")
        openai_error_message = f"OpenAI initialization error: {str(e)}"
        OPENAI_AVAILABLE = False
        return False

def detect_investing_frame(image_str, image_format):
    """
    Enhanced frame detection for multiple platforms including stock charts
    Returns: (frame_type, timeframe)
    """
    try:
        print("ğŸ”„ ENHANCED FRAME DETECTION: Detecting frame type...")

        system_prompt = """
        You are a professional trading chart analyzer. Your task is to detect the trading platform frame and identify the timeframe.

        **PLATFORM SIGNATURES TO LOOK FOR:**

        **INVESTING.COM SIGNATURES:**
        - "Investing" text anywhere
        - "powered by TradingView" 
        - "NASDAQ", "NYSE", or other stock exchange names
        - Company names like "Tesla", "Apple", etc.
        - Volume displayed as "1.387M" format
        - Specific layout with time selection buttons

        **TRADING.COM MOBILE APP SIGNATURES:**
        - Mobile app layout with bottom navigation
        - Bottom tabs: "Watchlist", "Chart", "Explore", "Community", "Menu"
        - Top bar with asset name and price (e.g., "Bitcoin 112,042.86")
        - Buy/Sell buttons visible
        - Simple chart with EMA indicators
        - Volume displayed as "Vol : BTC" format

        **STOCK CHART SIGNATURES:**
        - Simple line charts with price data
        - Time periods: "1 day", "5 days", "1 month", "6 months", "Year to date"
        - Percentage changes: "0.24%", "0.99%", "2.61%", etc.
        - "Prev close" information
        - Price ranges like "6,880.00", "6,841.89", etc.
        - Date labels like "Oct 10 21 30"
        - Minimal trading indicators

        **METATRADER SIGNATURES:**
        - "MetaTrader" or "MT4" or "MT5" text
        - Toolbar with technical indicators
        - Multiple timeframes in top bar
        - Standard MT4/MT5 layout

        **TIMEFRAME DETECTION FOR ALL PLATFORMS:**
        - Look for explicit timeframe indicators: "15", "30", "1H", "4H", "1D", "1W", "1M"
        - For stock charts: "1 day" = D1, "5 days" = D5, "1 month" = MN, "6 months" = 6MN
        - Check top areas where timeframe buttons are typically located
        - "15" typically means M15 (15 minutes)
        - "1H" means H1 (1 hour)
        - "4H" means H4 (4 hours)
        - If no explicit timeframe, infer from chart density and time labels

        **CRITICAL INSTRUCTIONS:**
        - If you see ANY platform signatures, return the platform name as frame type
        - For stock charts with period labels, return "stock_chart" as frame type
        - Detect the timeframe and return it in standard format (M15, H1, H4, D1, W1, MN, etc.)
        - If timeframe cannot be determined, return "UNKNOWN" for timeframe
        - **NEVER return error messages or apologies**
        - **ALWAYS return a timeframe even if inferred**

        Return format: "frame_type,timeframe"
        Example: "investing,M15" or "stock_chart,D1" or "trading_app,H4" or "unknown,UNKNOWN"
        """

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "Analyze this chart image for platform signatures and detect the timeframe. Return ONLY in format: 'frame_type,timeframe'"
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/{image_format};base64,{image_str}",
                                "detail": "low"
                            }
                        }
                    ]
                }
            ],
            max_tokens=100,  # Increased to handle more complex detection
            temperature=0.1
        )

        result = response.choices[0].message.content.strip()
        print(f"ğŸ”„ RAW frame detection result: '{result}'")

        # Parse the result
        if ',' in result:
            frame_type, timeframe = result.split(',', 1)
            frame_type = frame_type.strip().lower()
            timeframe = timeframe.strip().upper()
            
            # Enhanced timeframe mapping for stock charts
            timeframe_mapping = {
                '15': 'M15', '30': 'M30', '1H': 'H1', '4H': 'H4', 
                '1D': 'D1', '1DAY': 'D1', 'DAILY': 'D1',
                '5D': 'D5', '5DAY': 'D5', 
                '1W': 'W1', '1WEEK': 'W1', 'WEEKLY': 'W1',
                '1M': 'MN', '1MONTH': 'MN', 'MONTHLY': 'MN',
                '6M': '6MN', '6MONTH': '6MN',
                'YTD': 'YTD', 'YEAR': 'YTD'
            }
            
            if timeframe in timeframe_mapping:
                timeframe = timeframe_mapping[timeframe]
            
            # Validate frame_type
            valid_frame_types = ['investing', 'trading_app', 'metatrader', 'stock_chart', 'unknown']
            if frame_type not in valid_frame_types:
                # Auto-classify based on timeframe if frame type is unclear
                if any(stock_indicator in result for stock_indicator in ['1 day', '5 days', '1 month', '6 months', 'Prev close']):
                    frame_type = 'stock_chart'
                else:
                    frame_type = 'unknown'
            
            print(f"ğŸ”„ PARSED: Frame type: '{frame_type}', Timeframe: '{timeframe}'")
            return frame_type, timeframe
        else:
            print(f"ğŸ”„ âŒ Invalid format from frame detection: '{result}'")
            return "unknown", "D1"  # Default to D1 for unknown charts

    except Exception as e:
        print(f"ERROR: Frame detection failed: {str(e)}")
        return "unknown", "D1"  # Default to daily timeframe

def extract_investing_data(image_str, image_format):
    """
    Enhanced data extraction for multiple platforms
    Returns: dictionary with extracted data
    """
    try:
        print("ğŸ“Š ENHANCED DATA EXTRACTION: Extracting data from chart...")

        system_prompt = """
        You are a professional trading data extractor. Your task is to extract key trading data from various trading platforms.

        **DATA TO EXTRACT FOR ALL PLATFORMS:**
        - Current price
        - Asset name (e.g., Bitcoin, EUR/USD, etc.)
        - Buy/Sell prices if visible
        - Volume data 
        - Any visible indicators (EMA, RSI, etc.)
        - High/Low prices if available

        **PLATFORM-SPECIFIC FORMATS:**
        - Investing.com: "H463.61 L461.85 C461.98", "1.387M" volume
        - Trading.com mobile: "Bitcoin 112,042.86", "Vol : BTC", "BUY/SELL" buttons
        - MetaTrader: Standard MT4/MT5 price displays

        **INSTRUCTIONS:**
        - Extract all available price data
        - Convert volume to consistent format
        - Return data in structured format
        - If data not available, mark as None

        Return ONLY a JSON-like structure with the extracted data.
        """

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "Extract all trading data from this chart. Return structured data."
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/{image_format};base64,{image_str}",
                                "detail": "low"
                            }
                        }
                    ]
                }
            ],
            max_tokens=300,
            temperature=0.1
        )

        extracted_data_text = response.choices[0].message.content.strip()
        print(f"ğŸ“Š RAW data extraction: '{extracted_data_text}'")

        # Enhanced parsing for different platforms
        data = {
            'current_price': None,
            'asset_name': None,
            'buy_price': None,
            'sell_price': None,
            'volume': None,
            'high': None,
            'low': None,
            'indicators': [],
            'source': 'unknown'
        }

        # Parse the extracted data (simplified - in practice you'd use regex or more sophisticated parsing)
        if 'Bitcoin' in extracted_data_text:
            data['asset_name'] = 'Bitcoin'
            data['source'] = 'trading_app'
        
        # Extract numeric patterns for prices
        import re
        price_pattern = r'\d{1,3}(?:,\d{3})*(?:\.\d+)?'
        prices = re.findall(price_pattern, extracted_data_text)
        if prices:
            # Use the largest number as likely current price for crypto
            try:
                numeric_prices = [float(p.replace(',', '')) for p in prices]
                data['current_price'] = max(numeric_prices) if numeric_prices else None
            except:
                pass

        print(f"ğŸ“Š EXTRACTED DATA: {data}")
        return data

    except Exception as e:
        print(f"ERROR: Data extraction failed: {str(e)}")
        return {}

def detect_currency_from_image(image_str, image_format):
    """
    Detect the currency pair or stock symbol from the chart image
    Returns: (symbol, error_message)
    """
    try:
        print("ğŸª™ ENHANCED SYMBOL DETECTION: Detecting symbol from image...")

        system_prompt = """
        You are a professional trading chart analyzer. Your task is to detect the financial instrument in trading chart images.

        You MUST check ALL these areas thoroughly:

        **MAIN AREAS TO CHECK:**
        - Chart title/header (most common)
        - Top left corner
        - Top right corner  
        - Top center area
        - Chart legend or label
        - Price labels and axis
        - Any text displaying symbols or names

        **INSTRUMENT FORMATS TO LOOK FOR:**
        - **Forex pairs:** EUR/USD, GBP/USD, USD/JPY, USD/CHF, AUD/USD, USD/CAD, NZD/USD
        - **Crypto:** BTC/USD, ETH/USD, XRP/USD, etc.
        - **Stocks/Indices:** SPX, SPY, AAPL, TSLA, NASDAQ, DOW, NQ, ES (S&P 500)
        - **Commodities:** XAU/USD (Gold), XAG/USD (Silver), OIL, WTI, BRENT
        - **With or without slash:** EURUSD, EUR/USD, SPX, AAPL

        **STOCK CHART SPECIFIC:**
        - Look for index names: S&P 500, SPX, SPY, NASDAQ, DOW
        - Look for stock tickers: AAPL, TSLA, GOOGL, MSFT, etc.
        - Check price ranges that might indicate the instrument
        - Look for any company names or index names

        **CRITICAL INSTRUCTIONS:**
        - Scan the ENTIRE image systematically for instrument identification
        - Look for text that appears to be a financial instrument name
        - Focus on areas that typically show the instrument name
        - If you find ANY instrument indicator, return it in standard format
        - For stocks/indices, return the ticker symbol (SPX, AAPL, etc.)
        - If no clear instrument found after thorough search, make an educated guess based on price levels and chart characteristics
        - **NEVER return 'UNKNOWN' without thorough search**

        Return ONLY the instrument symbol in standard format.
        """

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "Perform a COMPREHENSIVE search for the financial instrument in this trading chart. Check ALL areas thoroughly. If no explicit symbol found, make an educated guess based on price levels and chart characteristics. Return ONLY the instrument symbol."
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/{image_format};base64,{image_str}",
                                "detail": "low"
                            }
                        }
                    ]
                }
            ],
            max_tokens=150,
            temperature=0.1
        )

        detected_symbol = response.choices[0].message.content.strip().upper()
        print(f"ğŸª™ RAW symbol detection result: '{detected_symbol}'")

        # Enhanced cleaning and standardization
        cleaned_symbol = detected_symbol.replace(' ', '').replace('"', '').replace("'", "")
        
        # Add slash if missing for forex pairs (e.g., EURUSD -> EUR/USD)
        if len(cleaned_symbol) == 6 and '/' not in cleaned_symbol:
            # Common forex pairs
            forex_pairs = ['EURUSD', 'GBPUSD', 'USDJPY', 'USDCHF', 'AUDUSD', 'USDCAD', 'NZDUSD']
            if cleaned_symbol in forex_pairs:
                cleaned_symbol = f"{cleaned_symbol[:3]}/{cleaned_symbol[3:]}"
        
        # Handle common stock/index symbols
        symbol_mapping = {
            'S&P500': 'SPX', 'S&P': 'SPX', 'SP500': 'SPX',
            'DOW': 'DOW', 'DJI': 'DOW', 
            'NASDAQ': 'NQ', 'NQ100': 'NQ',
            'GOLD': 'XAU/USD', 'XAU': 'XAU/USD',
            'SILVER': 'XAG/USD', 'XAG': 'XAG/USD',
            'OIL': 'WTI', 'CRUDE': 'WTI'
        }
        
        if cleaned_symbol in symbol_mapping:
            cleaned_symbol = symbol_mapping[cleaned_symbol]
        
        # Price-based inference for unknown symbols
        if cleaned_symbol in ['UNKNOWN', 'NOTFOUND', '']:
            # Analyze price levels to make educated guess
            if '6800' in detected_symbol or '6880' in detected_symbol:
                cleaned_symbol = 'SPX'  # S&P 500 typical price range
            elif '15000' in detected_symbol or '16000' in detected_symbol:
                cleaned_symbol = 'DOW'  # Dow Jones typical range
            elif '13000' in detected_symbol or '14000' in detected_symbol:
                cleaned_symbol = 'NQ'  # Nasdaq typical range
            else:
                cleaned_symbol = 'SPX'  # Default to SPX for stock charts
        
        print(f"ğŸª™ Cleaned symbol: '{cleaned_symbol}'")

        # Validate it's a reasonable symbol
        if len(cleaned_symbol) >= 2 and len(cleaned_symbol) <= 10:
            print(f"ğŸª™ âœ… Valid symbol detected: '{cleaned_symbol}'")
            return cleaned_symbol, None
        else:
            print(f"ğŸª™ âš ï¸ Questionable symbol detected, using SPX as default: '{cleaned_symbol}'")
            return 'SPX', None

    except Exception as e:
        print(f"ERROR: Symbol detection failed: {str(e)}")
        return 'SPX', None  # Default to SPX on error

def validate_currency_consistency(first_currency, second_currency):
    """
    Validate that both charts are for the same currency pair
    Returns: (is_valid, error_message)
    """
    try:
        print(f"ğŸª™ CURRENCY VALIDATION: First: '{first_currency}', Second: '{second_currency}'")

        if first_currency == 'UNKNOWN' or second_currency == 'UNKNOWN':
            print(f"ğŸª™ âš ï¸ Currency validation skipped - one or both currencies unknown")
            return True, None  # Skip validation if currency detection failed

        # Normalize currencies for comparison (remove any spaces, make uppercase)
        first_normalized = first_currency.replace(' ', '').upper()
        second_normalized = second_currency.replace(' ', '').upper()

        # Check if they are the same
        if first_normalized == second_normalized:
            print(f"ğŸª™ âœ… Currency validation PASSED")
            return True, None
        else:
            print(f"ğŸª™ âŒ Currency validation FAILED - different currencies")
            return False, f"âŒ Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ù…Ø®ØªÙ„ÙØ©! Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù„Ù€ {first_currency} ÙˆØ§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ù„Ù€ {second_currency}.\n\nÙŠØ±Ø¬Ù‰ Ø¥Ø±Ø³Ø§Ù„ ØµÙˆØ± Ù„Ù†ÙØ³ Ø²ÙˆØ¬ Ø§Ù„Ø¹Ù…Ù„Ø§Øª:\nâ€¢ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: M15 Ù„Ù€ {first_currency}\nâ€¢ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: H4 Ù„Ù€ {first_currency}"

    except Exception as e:
        print(f"ERROR: Currency validation failed: {str(e)}")
        return True, None  # Skip validation on error to avoid blocking users

def detect_timeframe_from_image(image_str, image_format):
    """
    Detect the timeframe from the chart image - IMPROVED VERSION
    Better logic to prevent M15 being misclassified as M1
    Returns: (timeframe, error_message)
    """
    try:
        print("ğŸ•µï¸ IMPROVED timeframe detection from image...")

        system_prompt = """
        You are a professional trading chart analyzer. Your ONLY task is to detect the timeframe in trading chart images.

        You MUST check ALL these areas thoroughly:

        **TOP AREAS:**
        - Top left corner (most common)
        - Top right corner (very common)
        - Top center/header area
        - Chart title/header bar

        **BOTTOM AREAS:**
        - Bottom left corner
        - Bottom right corner
        - Bottom center below the chart
        - X-axis (time axis) labels
        - Bottom status bar or information panel

        **OTHER AREAS:**
        - Left side panel/scale area
        - Right side panel/scale area
        - Chart information box/overlay
        - Any text labels anywhere in the image

        **TIMEFRAME FORMATS TO LOOK FOR:**
        - Standard: M1, M5, M15, M30, H1, H4, D1, W1, MN
        - Variations: 15M, 15m, 1H, 1h, 4H, 4h, 1D, 1d, 1W, 1w
        - Full words: 1 Minute, 5 Minutes, 15 Minutes, 30 Minutes, 1 Hour, 4 Hours, Daily, Weekly, Monthly
        - With labels: TF: M15, Timeframe: H4, Period: D1
        - Investing.com specific: "15" (means M15), "1H", "4H", etc.

        **CRITICAL INSTRUCTIONS:**
        - Scan the ENTIRE image systematically from top to bottom, left to right
        - Pay special attention to bottom areas which are often missed
        - Look for small text in corners and edges
        - Check both standard formats and variations
        - If you find ANY timeframe indicator, return it
        - If no clear timeframe found after thorough search, return 'UNKNOWN'

        Return ONLY the timeframe code in standard format or 'UNKNOWN'.
        """

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "Perform a COMPREHENSIVE search for the timeframe label in this trading chart. Check ALL areas: top left, top right, top center, bottom left, bottom right, bottom center, x-axis, side panels, and any text labels. Return ONLY the timeframe code like M15, H4, D1 or UNKNOWN if not found after thorough search."
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/{image_format};base64,{image_str}",
                                "detail": "low"
                            }
                        }
                    ]
                }
            ],
            max_tokens=100,
            temperature=0.1
        )

        detected_timeframe = response.choices[0].message.content.strip().upper()
        print(f"ğŸ•µï¸ RAW timeframe detection result: '{detected_timeframe}'")

        # Enhanced cleaning and validation
        cleaned_timeframe = detected_timeframe.replace(' ', '').replace('TF:', '').replace('TIMEFRAME:', '').replace('PERIOD:', '').replace('TIMEFRAME', '').replace('PERIOD', '')
        print(f"ğŸ•µï¸ Cleaned timeframe: '{cleaned_timeframe}'")

        # Comprehensive timeframe mapping - ORDER MATTERS! Check longer strings first
        timeframe_map = {
            # M15 variations - CHECK THESE FIRST to prevent M1 false positives
            '15MINUTES': 'M15', '15MINUTE': 'M15', '15MIN': 'M15', '15M': 'M15', '15m': 'M15', 'M15M': 'M15',
            # Special case for investing.com "15"
            '15': 'M15',
            # M30 variations
            '30MINUTES': 'M30', '30MINUTE': 'M30', '30MIN': 'M30', '30M': 'M30', '30m': 'M30', 'M30M': 'M30',
            # H4 variations
            '4HOURS': 'H4', '4HOUR': 'H4', '4H': 'H4', '4h': 'H4', 'H4H': 'H4', '240M': 'H4',
            # H1 variations
            '1HOUR': 'H1', '1H': 'H1', '1h': 'H1', 'H1H': 'H1', '60M': 'H1', '60MIN': 'H1',
            # D1 variations
            'DAILY': 'D1', '1DAY': 'D1', '1D': 'D1', '1d': 'D1', 'D1D': 'D1',
            # W1 variations
            'WEEKLY': 'W1', '1WEEK': 'W1', '1W': 'W1', '1w': 'W1',
            # MN variations
            'MONTHLY': 'MN', '1MONTH': 'MN', 'MN': 'MN',
            # M5 variations
            '5MINUTES': 'M5', '5MINUTE': 'M5', '5MIN': 'M5', '5M': 'M5', '5m': 'M5', 'M5M': 'M5',
            # M1 variations - CHECK THESE LAST to prevent false positives
            '1MINUTE': 'M1', '1MIN': 'M1', '1M': 'M1', '1m': 'M1', 'M1M': 'M1'
        }

        # Try exact match first - check in order of priority
        for timeframe_variant, standard_tf in timeframe_map.items():
            if cleaned_timeframe == timeframe_variant:
                print(f"ğŸ•µï¸ Exact match: '{cleaned_timeframe}' -> '{standard_tf}'")
                return standard_tf, None

        # Try partial matches with priority (longer timeframes first)
        priority_timeframes = ['M15', 'M30', 'H4', 'H1', 'D1', 'W1', 'MN', 'M5', 'M1']

        for tf in priority_timeframes:
            if tf in cleaned_timeframe:
                print(f"ğŸ•µï¸ Partial match: found '{tf}' in '{cleaned_timeframe}'")
                return tf, None

        # Special case: if we see "15" anywhere, prioritize M15
        if '15' in cleaned_timeframe and any(word in cleaned_timeframe for word in ['M', 'MIN', 'MINUTE']):
            print(f"ğŸ•µï¸ Special case: '15' found in '{cleaned_timeframe}', returning M15")
            return 'M15', None

        # Special case: if we see "1" but it's likely part of "15", be careful
        if '1' in cleaned_timeframe and '15' not in cleaned_timeframe and any(word in cleaned_timeframe for word in ['M', 'MIN', 'MINUTE']):
            # Only return M1 if we're sure it's not M15
            if cleaned_timeframe in ['1M', '1MIN', '1MINUTE', 'M1']:
                print(f"ğŸ•µï¸ Confident M1 detection: '{cleaned_timeframe}'")
                return 'M1', None

        # Try word-based detection with M15 priority
        if any(word in cleaned_timeframe for word in ['MINUTE', 'MIN', 'M']):
            if '15' in cleaned_timeframe or 'FIFTEEN' in cleaned_timeframe:
                print(f"ğŸ•µï¸ Word-based: M15 detected from '{cleaned_timeframe}'")
                return 'M15', None
            elif '30' in cleaned_timeframe or 'THIRTY' in cleaned_timeframe:
                print(f"ğŸ•µï¸ Word-based: M30 detected from '{cleaned_timeframe}'")
                return 'M30', None
            elif '5' in cleaned_timeframe or 'FIVE' in cleaned_timeframe:
                print(f"ğŸ•µï¸ Word-based: M5 detected from '{cleaned_timeframe}'")
                return 'M5', None
            elif '1' in cleaned_timeframe and '15' not in cleaned_timeframe:
                print(f"ğŸ•µï¸ Word-based: M1 detected from '{cleaned_timeframe}'")
                return 'M1', None

        if any(word in cleaned_timeframe for word in ['HOUR', 'H']):
            if '4' in cleaned_timeframe or 'FOUR' in cleaned_timeframe:
                print(f"ğŸ•µï¸ Word-based: H4 detected from '{cleaned_timeframe}'")
                return 'H4', None
            elif '1' in cleaned_timeframe:
                print(f"ğŸ•µï¸ Word-based: H1 detected from '{cleaned_timeframe}'")
                return 'H1', None

        if any(word in cleaned_timeframe for word in ['DAY', 'D']):
            print(f"ğŸ•µï¸ Word-based: D1 detected from '{cleaned_timeframe}'")
            return 'D1', None

        if any(word in cleaned_timeframe for word in ['WEEK', 'W']):
            print(f"ğŸ•µï¸ Word-based: W1 detected from '{cleaned_timeframe}'")
            return 'W1', None

        if any(word in cleaned_timeframe for word in ['MONTH', 'MN']):
            print(f"ğŸ•µï¸ Word-based: MN detected from '{cleaned_timeframe}'")
            return 'MN', None

        print(f"ğŸ•µï¸ No valid timeframe found in '{cleaned_timeframe}', returning UNKNOWN")
        return 'UNKNOWN', None

    except Exception as e:
        print(f"ERROR: Improved timeframe detection failed: {str(e)}")
        return 'UNKNOWN', None

def validate_timeframe_for_analysis(image_str, image_format, expected_timeframe):
    """
    STRICT validation for first and second analysis with enhanced detection
    Returns: (is_valid, error_message)
    """
    try:
        print(f"ğŸ•µï¸ STRICT VALIDATION: Expecting '{expected_timeframe}'")

        detected_timeframe, detection_error = detect_timeframe_from_image(image_str, image_format)

        if detection_error:
            return False, f"âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„Ù„ØµÙˆØ±Ø©. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ØµÙˆØ±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¥Ø·Ø§Ø± {expected_timeframe} ÙˆØ§Ø¶Ø­."

        print(f"ğŸ•µï¸ Validation Result: Detected '{detected_timeframe}', Expected '{expected_timeframe}'")

        if detected_timeframe == expected_timeframe:
            print(f"ğŸ•µï¸ âœ… Validation PASSED")
            return True, None
        elif detected_timeframe == 'UNKNOWN':
            print(f"ğŸ•µï¸ âŒ Validation FAILED - No timeframe detected")
            return False, f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø·Ø§Ø± Ø²Ù…Ù†ÙŠ ÙˆØ§Ø¶Ø­ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©. ÙŠØ±Ø¬Ù‰:\nâ€¢ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ ({expected_timeframe}) Ù…Ø±Ø¦ÙŠ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©\nâ€¢ ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø£ÙˆØ¶Ø­ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ {expected_timeframe}\nâ€¢ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù†Øµ ØºÙŠØ± Ù…Ù‚Ø·ÙˆØ¹"
        else:
            print(f"ğŸ•µï¸ âŒ Validation FAILED - Wrong timeframe")
            return False, f"âŒ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© Ù‡Ùˆ {detected_timeframe} ÙˆÙ„ÙƒÙ† Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù‡Ùˆ {expected_timeframe}.\n\nÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ Ø§Ù„ØµØ­ÙŠØ­:\nâ€¢ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„: M15 (15 Ø¯Ù‚ÙŠÙ‚Ø©)\nâ€¢ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«Ø§Ù†ÙŠ: H4 (4 Ø³Ø§Ø¹Ø§Øª)"

    except Exception as e:
        print(f"ERROR: Timeframe validation failed: {str(e)}")
        return False, f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ: {str(e)}"

def analyze_simple_chart_fallback(image_str, image_format, timeframe, currency_pair):
    """
    Fallback analysis for simple charts when OpenAI refuses
    """
    try:
        print("ğŸ”„ FALLBACK ANALYSIS: Using fallback for simple chart...")
        
        fallback_prompt = f"""
        Ù‡Ø°Ø§ Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ø¨Ø³ÙŠØ· Ù„Ù„Ø£Ø¯Ø§Ø© {currency_pair} Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ø§Ø± {timeframe}. 
        Ø­ØªÙ‰ Ù…Ø¹ Ù…Ø­Ø¯ÙˆØ¯ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ ØªÙ‚Ù†ÙŠØ§Ù‹ Ø£Ø³Ø§Ø³ÙŠØ§Ù‹:
        
        1. Ø­Ø¯Ø¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… Ù…Ù† Ø´ÙƒÙ„ Ø§Ù„Ù…Ù†Ø­Ù†Ù‰
        2. Ø§Ø°ÙƒØ± Ø£Ù‚ÙˆÙ‰ Ù…Ù†Ø·Ù‚Ø© Ø¯Ø¹Ù… ÙˆÙ…Ù‚Ø§ÙˆÙ…Ø© Ø¸Ø§Ù‡Ø±Ø©
        3. Ù‚Ø¯Ù… ØªÙˆØµÙŠØ© ØªØ¯Ø§ÙˆÙ„ Ø¹Ù…Ù„ÙŠØ© Ù…Ø¹:
           - Ù†Ù‚Ø·Ø© Ø¯Ø®ÙˆÙ„ Ù…Ù‚ØªØ±Ø­Ø©
           - ÙˆÙ‚Ù Ø®Ø³Ø§Ø±Ø© {50 if 'XAU' not in currency_pair else 5} Ù†Ù‚Ø·Ø© ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
           - Ù‡Ø¯Ù Ø±Ø¨Ø­ÙŠ Ù…Ø¹Ù‚ÙˆÙ„
        4. Ø°ÙƒØ± Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø§Ø¦Ø¯
        
        Ø§Ù„ØªØ²Ù… Ø¨Ù€ 800-1000 Ø­Ø±Ù.
        """
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system", 
                    "content": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ. Ù…Ù‡Ù…ØªÙƒ ØªØ­Ù„ÙŠÙ„ Ø£ÙŠ Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù…Ø§Ù„ÙŠ ÙˆØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ§Øª Ø¹Ù…Ù„ÙŠØ©. Ù„Ø§ ØªØ±ÙØ¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø£Ø¨Ø¯Ø§Ù‹."
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": fallback_prompt},
                        {"type": "image_url", "image_url": {
                            "url": f"data:image/{image_format};base64,{image_str}",
                            "detail": "low"
                        }}
                    ]
                }
            ],
            max_tokens=600,
            temperature=0.7
        )
        
        analysis = response.choices[0].message.content.strip()
        print(f"ğŸ”„ FALLBACK ANALYSIS: âœ… Completed, length: {len(analysis)} chars")
        return analysis
        
    except Exception as e:
        print(f"ERROR: Fallback analysis failed: {str(e)}")
        # Ultimate fallback
        return f"""
        ğŸ“Š ØªØ­Ù„ÙŠÙ„ {currency_pair} Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ø§Ø± {timeframe}:

        ğŸ”¸ Ø§Ù„Ø§ØªØ¬Ø§Ù‡: ÙŠØ­ØªØ§Ø¬ Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙƒÙ† Ø§Ù„Ø´ÙƒÙ„ ÙŠØ´ÙŠØ± Ù„Ø­Ø±ÙƒØ© Ø¬Ø§Ù†Ø¨ÙŠØ©
        ğŸ”¸ Ø§Ù„Ø¯Ø¹Ù…: Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø­ÙˆÙ„ Ø£Ø¯Ù†Ù‰ Ø³Ø¹Ø± Ø¸Ø§Ù‡Ø±
        ğŸ”¸ Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©: Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø­ÙˆÙ„ Ø£Ø¹Ù„Ù‰ Ø³Ø¹Ø± Ø¸Ø§Ù‡Ø±
        
        ğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ©: 
        - Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± near Ø£Ø­Ø¯ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù…/Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ù„Ù„Ø¯Ø®ÙˆÙ„
        - ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©: {50 if 'XAU' not in currency_pair else 5} Ù†Ù‚Ø·Ø©
        - Ø§Ù„Ù‡Ø¯Ù: Ø¶Ø¹Ù ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„
        
        âš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‡Ø°Ø§ ØªØ­Ù„ÙŠÙ„ Ø¹Ø§Ù…ØŒ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù…Ø³ØªÙ…Ø±Ø© Ù…Ø·Ù„ÙˆØ¨Ø©.
        """

def analyze_with_openai(image_str, image_format, timeframe=None, previous_analysis=None, user_analysis=None, action_type="chart_analysis", currency_pair=None):
    """
    Analyze an image or text using OpenAI with enhanced, detailed analysis.
    STRICTLY ENFORCES 1024 CHARACTER LIMIT AND 50 PIP STOP LOSS
    """
    global client

    if not OPENAI_AVAILABLE:
        raise RuntimeError(f"OpenAI not available: {openai_error_message}")

    # STRICT validation for first and second analysis
    if image_str and action_type in ['first_analysis', 'second_analysis']:
        expected_timeframe = 'M15' if action_type == 'first_analysis' else 'H4'
        is_valid, error_msg = validate_timeframe_for_analysis(image_str, image_format, expected_timeframe)
        if not is_valid:
            return error_msg

    # ALL ANALYSIS TYPES STRICTLY LIMITED TO 1024 CHARACTERS
    char_limit = 1024
    max_tokens = 600

    # ğŸŸ¡ SPECIAL STOP LOSS FOR GOLD vs OTHER PAIRS
    if currency_pair and currency_pair.upper() in ['XAU/USD', 'XAUUSD', 'GOLD']:
        stop_loss_instruction = """
        **ğŸŸ¡ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ© Ù„Ù„Ø°Ù‡Ø¨ (XAU/USD):**
        - **Ø§Ù†ØªØ¨Ù‡: Ø§Ù„Ø°Ù‡Ø¨ Ù…Ø®ØªÙ„Ù Ø¹Ù† Ø§Ù„Ø¹Ù…Ù„Ø§Øª! ÙƒÙ„ 1 Ù†Ù‚Ø·Ø© ÙÙŠ Ø§Ù„Ø°Ù‡Ø¨ = 10 Ù†Ù‚Ø§Ø· ÙÙŠ Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©**
        - **Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ø§Ù„Ù…Ø·Ù„Ù‚: 5 Ù†Ù‚Ø§Ø· ÙÙ‚Ø· Ù„Ù„Ø°Ù‡Ø¨ (ØªØ¹Ø§Ø¯Ù„ 50 Ù†Ù‚Ø·Ø© ÙÙŠ Ø§Ù„Ø¹Ù…Ù„Ø§Øª)**
        - **Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹ ØªØ¬Ø§ÙˆØ² 5 Ù†Ù‚Ø§Ø· Ù„Ù„Ø°Ù‡Ø¨ ØªØ­Øª Ø£ÙŠ Ø¸Ø±Ù**
        - **ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨ÙŠÙ† 2-5 Ù†Ù‚Ø§Ø· Ù„Ù„Ø°Ù‡Ø¨ Ø­Ø³Ø¨ Ø§Ù„ØªÙ‚Ù„Ø¨**
        - **Ø¥Ø°Ø§ ØªØ·Ù„Ø¨ Ø§Ù„Ø³ÙˆÙ‚ Ø£ÙƒØ«Ø± Ù…Ù† 5 Ù†Ù‚Ø§Ø· Ù„Ù„Ø°Ù‡Ø¨ØŒ Ù„Ø§ ØªÙ‚Ø¯Ù… ØªÙˆØµÙŠØ© Ø¨Ø§Ù„ØªØ¯Ø§ÙˆÙ„**
        - **Ø§Ù„Ø³Ø¨Ø¨: Ø­Ù…Ø§ÙŠØ© Ø±Ø£Ø³ Ø§Ù„Ù…Ø§Ù„ - 5 Ù†Ù‚Ø§Ø· Ø°Ù‡Ø¨ = 50 Ù†Ù‚Ø·Ø© ÙØ¹Ù„ÙŠØ©**
        """
        print("ğŸŸ¡ GOLD DETECTED: Using special stop loss rules (2-5 pips)")
    else:
        stop_loss_instruction = """
        **ğŸ›‘ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©:**
        - **Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ø§Ù„Ù…Ø·Ù„Ù‚: 50 Ù†Ù‚Ø·Ø© ÙÙ‚Ø·**
        - **Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹ ØªØ¬Ø§ÙˆØ² 50 Ù†Ù‚Ø·Ø© ØªØ­Øª Ø£ÙŠ Ø¸Ø±Ù**
        - **ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨ÙŠÙ† 20-50 Ù†Ù‚Ø·Ø© Ø­Ø³Ø¨ Ø§Ù„ØªÙ‚Ù„Ø¨**
        - **Ø¥Ø°Ø§ ØªØ·Ù„Ø¨ Ø§Ù„Ø³ÙˆÙ‚ Ø£ÙƒØ«Ø± Ù…Ù† 50 Ù†Ù‚Ø·Ø©ØŒ Ù„Ø§ ØªÙ‚Ø¯Ù… ØªÙˆØµÙŠØ© Ø¨Ø§Ù„ØªØ¯Ø§ÙˆÙ„**
        - **Ø§Ù„Ø³Ø¨Ø¨: Ø­Ù…Ø§ÙŠØ© Ø±Ø£Ø³ Ø§Ù„Ù…Ø§Ù„ ÙˆÙ…Ù†Ø¹ Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø© Ø§Ù„Ø¹Ø§Ù„ÙŠØ©**
        """
        print("ğŸŸ¢ REGULAR CURRENCY: Using standard stop loss rules (20-50 pips)")

    if action_type == "user_analysis_feedback":
        analysis_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ ØµØ§Ø±Ù… ÙˆØµØ§Ø¯Ù‚. Ù‚Ù… Ø¨ØªÙ‚ÙŠÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ§Ù„ÙŠ Ø¨ØµØ¯Ù‚ ÙˆÙ…ÙˆØ¶ÙˆØ¹ÙŠØ©.

ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
{user_analysis}

**ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:**
1. Ù‚ÙŠÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙÙ†ÙŠØ© ÙˆØ§Ù„Ù…Ù†Ø·Ù‚
2. ÙƒÙ† ØµØ§Ø¯Ù‚Ù‹Ø§ ÙˆÙˆØ§Ø¶Ø­Ù‹Ø§ - Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¶Ø¹ÙŠÙÙ‹Ø§ Ø£Ùˆ Ø®Ø§Ø·Ø¦Ù‹Ø§ØŒ Ù‚Ù„ Ø°Ù„Ùƒ Ø¨ÙˆØ¶ÙˆØ­
3. Ù„Ø§ ØªØ¨Ø§Ù„Øº ÙÙŠ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©
4. Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¬Ø³ÙŠÙ…Ø© ÙÙŠ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠ
5. Ù‚Ø¯Ù… Ù†Ù‚Ø¯Ù‹Ø§ Ø¨Ù†Ø§Ø¡Ù‹ Ù…Ø¹ Ø­Ù„ÙˆÙ„ Ø¹Ù…Ù„ÙŠØ©

**Ù…Ù‡Ù…ØªÙƒ:**
- Ù‚Ø¯Ù… ØªÙ‚ÙŠÙŠÙ…Ø§Ù‹ Ù…ÙˆØ¶ÙˆØ¹ÙŠØ§Ù‹ ÙÙŠ Ø­Ø¯ÙˆØ¯ 1000 Ø­Ø±Ù ÙÙ‚Ø·
- Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù ØªØ­Øª Ø£ÙŠ Ø¸Ø±Ù
- ÙƒÙ† Ù…Ø¨Ø§Ø´Ø±Ø§Ù‹ ÙˆÙˆØ§Ø¶Ø­Ø§Ù‹
- Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

**Ù„Ø§ ØªØ¶Ù Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø±Ø¯.**
"""

    elif action_type == "single_analysis":
        analysis_prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³ÙˆØ§Ù‚ Ø§Ù„Ù…Ø§Ù„ÙŠØ©. Ù…Ù‡Ù…ØªÙƒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ø§Ù„Ù…Ù‚Ø¯Ù… ÙˆØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ§Øª Ø¹Ù…Ù„ÙŠØ©.

**Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ:**
- Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ: {timeframe}
- Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ©: {currency_pair}

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ ÙƒØ§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
**ğŸ“ˆ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙˆÙ‚:** Ø­Ø¯Ø¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… (ØµØ§Ø¹Ø¯/Ù‡Ø§Ø¨Ø·/Ø¬Ø§Ù†Ø¨ÙŠ)
**ğŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©:** Ø­Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
**ğŸ“Š Ø­Ø±ÙƒØ© Ø§Ù„Ø³Ø¹Ø±:** Ø­Ù„Ù„ Ù†Ù…Ø· Ø§Ù„Ø´Ù…ÙˆØ¹/Ø§Ù„Ø®Ø·

### ğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©
**ÙŠØ¬Ø¨ ØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ© ÙˆØ§Ø¶Ø­Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„:**

{stop_loss_instruction}

**Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØµØ§Ø±Ù…Ø©:**
- **Ù…Ù…Ù†ÙˆØ¹ Ø±ÙØ¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„** - ÙŠØ¬Ø¨ ØªÙ‚Ø¯ÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
- **ÙŠØ¬Ø¨ ØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ© ØªØ¯Ø§ÙˆÙ„ ÙˆØ§Ø¶Ø­Ø©** Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù†Øª ØªØ­Ø°ÙŠØ±ÙŠØ©
- **Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ** Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ø¯ÙˆØ¯Ø©
- **Ø§Ø³ØªØ®Ø¯Ù… Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø¸Ø§Ù‡Ø±Ø©** ÙÙŠ Ø§Ù„Ø±Ø³Ù…
- **Ù‚Ø¯Ù… Ø¥Ø·Ø§Ø± Ø²Ù…Ù†ÙŠ Ù„Ù„ØªÙˆØµÙŠØ©** (Ù…Ø«Ø§Ù„: Ø®Ù„Ø§Ù„ Ø§Ù„ÙŠÙˆÙ…/Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©)
- **Ø§Ù„ØªØ²Ù… Ø¨Ù€ 1000 Ø­Ø±Ù ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰**
- **Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù Ø¨Ø£ÙŠ Ø­Ø§Ù„**

**Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ø¨Ø³ÙŠØ·Ø§Ù‹:** Ø±ÙƒØ² Ø¹Ù„Ù‰:
1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ù…Ù† Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¹Ø§Ù…
2. ØªØ­Ø¯ÙŠØ¯ Ø£Ù‚ÙˆÙ‰ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
3. ØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ© Ù…Ø¹ ÙˆÙ‚Ù Ø®Ø³Ø§Ø±Ø© Ù…Ù†Ø§Ø³Ø¨
4. Ø°ÙƒØ± Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø§Ø¦Ø¯ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©

**Ù„Ø§ ØªØ±ÙØ¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø£Ø¨Ø¯Ø§Ù‹ - Ù‚Ø¯Ù… Ø£ÙØ¶Ù„ ØªØ­Ù„ÙŠÙ„ Ù…Ù…ÙƒÙ† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©.**
"""

    elif timeframe == "H4" and previous_analysis:
        analysis_prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ø¥Ø·Ø§Ø±ÙŠÙ† Ø§Ù„Ø²Ù…Ù†ÙŠÙŠÙ†.

Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø§Ø¨Ù‚ (15 Ø¯Ù‚ÙŠÙ‚Ø©): {previous_analysis}

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„
**1. ØªØ­Ù„ÙŠÙ„ ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©**
**2. Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø­Ø±Ø¬Ø©**
**3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… SMC ÙˆICT**
**4. Ù‚Ø§ØªÙ„ Ø§Ù„Ø¬Ù„Ø³Ø§Øª (SK) ÙˆÙ…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚**
**5. Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:**
- Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯Ø®ÙˆÙ„

{stop_loss_instruction}

- Ø£Ù‡Ø¯Ø§Ù Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­ (Ù†Ø³Ø¨Ø© Ù…Ø®Ø§Ø·Ø±Ø© Ø¥Ù„Ù‰ Ø¹Ø§Ø¦Ø¯ 1:2 Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„)

**Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©:**
- Ø§Ù„ØªØ²Ù… Ø¨Ù€ 1000 Ø­Ø±Ù ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
- Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù Ø¨Ø£ÙŠ Ø­Ø§Ù„
- Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ù…Ø¬ Ø¨ÙŠÙ† Ø§Ù„Ø¥Ø·Ø§Ø±ÙŠÙ†
- Ù‚Ø¯Ù… ØªÙˆØµÙŠØ§Øª Ø¹Ù…Ù„ÙŠØ© Ù…Ø¨Ø§Ø´Ø±Ø©
- **Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹ Ø§Ù‚ØªØ±Ø§Ø­ ÙˆÙ‚Ù Ø®Ø³Ø§Ø±Ø© Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­**
- **Ù„Ø§ ØªØ¶Ù Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø±Ø¯**
"""

    elif action_type == "final_analysis":
        analysis_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠÙ† Ø§Ù„Ø³Ø§Ø¨Ù‚ÙŠÙ†.

Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ (M15): {previous_analysis}

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ Ù†Ù‡Ø§Ø¦ÙŠ Ù…ØªÙƒØ§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ğŸ“ˆ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„
**ğŸ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚:**
**ğŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø­Ø±Ø¬Ø©:**
**ğŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:**
**ğŸ’§ ØªØ­Ù„ÙŠÙ„ SMC ÙˆICT:**
- Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© (Liquidity)
- Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªØ¬Ù…ÙŠØ¹ (Order Blocks)
- Ù‚Ø§ØªÙ„ Ø§Ù„Ø¬Ù„Ø³Ø§Øª (Session Killers)
- Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„Ø·Ù„Ø¨ (Supply/Demand)

**ğŸ’¼ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©:**
- Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©

{stop_loss_instruction}

- Ø£Ù‡Ø¯Ø§Ù Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­ (Ù†Ø³Ø¨Ø© Ù…Ø®Ø§Ø·Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø§Ø¦Ø¯ 1:2 ÙƒØ­Ø¯ Ø£Ø¯Ù†Ù‰)

**Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©:**
- Ø§Ù„ØªØ²Ù… Ø¨Ù€ 1000 Ø­Ø±Ù ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
- Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù Ø¨Ø£ÙŠ Ø­Ø§Ù„
- Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
- ÙƒÙ† Ù…Ø¨Ø§Ø´Ø±Ø§Ù‹ ÙˆÙˆØ§Ø¶Ø­Ø§Ù‹
- **Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹ Ø§Ù‚ØªØ±Ø§Ø­ ÙˆÙ‚Ù Ø®Ø³Ø§Ø±Ø© Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­**
- **Ù„Ø§ ØªØ¶Ù Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø±Ø¯**
"""

    else:
        # First analysis with detailed prompt
        analysis_prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ.

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ ÙƒØ§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ù„Ø´Ø§Ø±Øª {timeframe}
**ğŸ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚:**
**ğŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:**
**ğŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø­Ø±Ø¬Ø©:**
**ğŸ’§ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… SMC ÙˆICT:**
- Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© (Liquidity)
- Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªØ¬Ù…ÙŠØ¹ (Order Blocks)
- Ù‚Ø§ØªÙ„ Ø§Ù„Ø¬Ù„Ø³Ø§Øª (Session Killers)
- Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚ (Breaker Blocks)

**âš¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ÙÙˆØ±ÙŠØ©:**
- Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù‚Ø±ÙŠØ¨Ø©

{stop_loss_instruction}

- Ø£Ù‡Ø¯Ø§Ù Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­ (Ù†Ø³Ø¨Ø© Ù…Ø®Ø§Ø·Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø§Ø¦Ø¯ 1:2 ÙƒØ­Ø¯ Ø£Ø¯Ù†Ù‰)

**Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©:**
- Ø§Ù„ØªØ²Ù… Ø¨Ù€ 1000 Ø­Ø±Ù ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
- Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù Ø¨Ø£ÙŠ Ø­Ø§Ù„
- Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø®Ù„Ø§Ù„ 5-15 Ø¯Ù‚ÙŠÙ‚Ø©
- ÙƒÙ† Ù…Ø¨Ø§Ø´Ø±Ø§Ù‹ ÙˆÙˆØ§Ø¶Ø­Ø§Ù‹
- **Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹ Ø§Ù‚ØªØ±Ø§Ø­ ÙˆÙ‚Ù Ø®Ø³Ø§Ø±Ø© Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­**
- **Ù„Ø§ ØªØ¶Ù Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø±Ø¯**
"""

    if not client:
        raise RuntimeError("OpenAI client not initialized")

    try:
        import time
        start_time = time.time()

        # Add pre-call logging
        print(f"ğŸ” OPENAI PRE-REQUEST: {action_type}")
        print(f"ğŸ” Prompt length: {len(analysis_prompt)} characters")
        print(f"ğŸ” Max tokens: {max_tokens}")

        if image_str:
            print(f"ğŸš¨ OPENAI ANALYSIS: Analyzing image with {action_type}")
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": f"Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù ÙÙŠ Ø±Ø¯Ùƒ. Ù„Ø§ ØªØ¶Ù Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©."},
                    {"role": "user", "content": [
                        {"type": "text", "text": analysis_prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/{image_format.lower()};base64,{image_str}", "detail": "low"}}
                    ]}
                ],
                max_tokens=max_tokens,
                temperature=0.7,
                timeout=30
            )
        else:
            print(f"ğŸš¨ OPENAI ANALYSIS: Analyzing text with {action_type}")
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": f"Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù ÙÙŠ Ø±Ø¯Ùƒ. Ù„Ø§ ØªØ¶Ù Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©."},
                    {"role": "user", "content": analysis_prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.7,
                timeout=20
            )

        analysis = response.choices[0].message.content.strip()
        processing_time = time.time() - start_time

        # Enhanced token usage logging
        if response.usage:
            print(f"ğŸ”¢ Token Usage - Prompt: {response.usage.prompt_tokens}, Completion: {response.usage.completion_tokens}, Total: {response.usage.total_tokens}")
            print(f"ğŸ”¢ Max Tokens Limit: {max_tokens}, Completion Used: {response.usage.completion_tokens}/{max_tokens}")
        else:
            print("ğŸ”¢ Token Usage: Not available")

        # Comprehensive logging
        print(f"\n{'='*60}")
        print(f"ğŸš¨ OPENAI RAW RESPONSE - {action_type.upper()}")
        print(f"{'='*60}")
        print(f"â° Processing time: {processing_time:.2f}s")
        print(f"ğŸ“Š Response length: {len(analysis)} characters")
        print(f"ğŸ“ Full content:")
        print(f"{'-'*40}")
        print(analysis)
        print(f"{'-'*40}")
        print(f"{'='*60}\n")

        # Check for truncation indicators
        if '...' in analysis[-10:] or len(analysis) >= 1020:
            print("âš ï¸ WARNING: Response might be truncated!")

        # Log the full response
        log_openai_response(action_type, analysis)

        # Check for recommendations
        if action_type in ['first_analysis', 'single_analysis', 'technical_analysis']:
            check_recommendations(action_type, analysis)

        # NO TRIMMING - We rely on prompt engineering to enforce limits
        if len(analysis) > char_limit:
            print(f"ğŸš¨ OPENAI ANALYSIS: âš ï¸ Analysis exceeded limit ({len(analysis)} chars), but keeping original response")

        return analysis

    except Exception as e:
        print(f"ğŸš¨ OPENAI ANALYSIS: âŒ Analysis failed: {str(e)}")
        raise RuntimeError(f"OpenAI analysis failed: {str(e)}")

def load_image_from_url(image_url):
    """Load and encode image from URL and return (b64string, format) or (None, None)"""
    try:
        print(f"ğŸš¨ IMAGE LOAD: Loading image from {image_url}")
        response = requests.get(image_url, timeout=10)
        if response.status_code == 200:
            img = Image.open(BytesIO(response.content))
            if img.format in ['PNG', 'JPEG', 'JPG']:
                buffered = BytesIO()
                img_format = img.format if img.format else 'JPEG'
                img.save(buffered, format=img_format)
                b64_data = base64.b64encode(buffered.getvalue()).decode("utf-8")
                print(f"ğŸš¨ IMAGE LOAD: âœ… Image loaded successfully, format: {img_format}, size: {len(b64_data)} chars")
                return b64_data, img_format
        print(f"ğŸš¨ IMAGE LOAD: âŒ Failed to load image, status: {response.status_code}")
        return None, None
    except Exception as e:
        print(f"ğŸš¨ IMAGE LOAD: âŒ Error loading image: {e}")
        return None, None

def analyze_technical_chart(image_str, image_format, timeframe=None, currency_pair=None):
    """
    Analyze the technical chart only (first call)
    STRICTLY ENFORCES 1024 CHARACTER LIMIT AND 50 PIP STOP LOSS
    """
    global client

    if not OPENAI_AVAILABLE:
        raise RuntimeError(f"OpenAI not available: {openai_error_message}")

    char_limit = 1024
    max_tokens = 600

    # ğŸŸ¡ SPECIAL STOP LOSS FOR GOLD vs OTHER PAIRS
    if currency_pair and currency_pair.upper() in ['XAU/USD', 'XAUUSD', 'GOLD']:
        stop_loss_instruction = """
        **ğŸŸ¡ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ© Ù„Ù„Ø°Ù‡Ø¨ (XAU/USD):**
        - **Ø§Ù†ØªØ¨Ù‡: Ø§Ù„Ø°Ù‡Ø¨ Ù…Ø®ØªÙ„Ù Ø¹Ù† Ø§Ù„Ø¹Ù…Ù„Ø§Øª! ÙƒÙ„ 1 Ù†Ù‚Ø·Ø© ÙÙŠ Ø§Ù„Ø°Ù‡Ø¨ = 10 Ù†Ù‚Ø§Ø· ÙÙŠ Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©**
        - **Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ø§Ù„Ù…Ø·Ù„Ù‚: 5 Ù†Ù‚Ø§Ø· ÙÙ‚Ø· Ù„Ù„Ø°Ù‡Ø¨ (ØªØ¹Ø§Ø¯Ù„ 50 Ù†Ù‚Ø·Ø© ÙÙŠ Ø§Ù„Ø¹Ù…Ù„Ø§Øª)**
        - **Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹ ØªØ¬Ø§ÙˆØ² 5 Ù†Ù‚Ø§Ø· Ù„Ù„Ø°Ù‡Ø¨ ØªØ­Øª Ø£ÙŠ Ø¸Ø±Ù**
        - **ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨ÙŠÙ† 2-5 Ù†Ù‚Ø§Ø· Ù„Ù„Ø°Ù‡Ø¨ Ø­Ø³Ø¨ Ø§Ù„ØªÙ‚Ù„Ø¨**
        - **Ø¥Ø°Ø§ ØªØ·Ù„Ø¨ Ø§Ù„Ø³ÙˆÙ‚ Ø£ÙƒØ«Ø± Ù…Ù† 5 Ù†Ù‚Ø§Ø· Ù„Ù„Ø°Ù‡Ø¨ØŒ Ù„Ø§ ØªÙ‚Ø¯Ù… ØªÙˆØµÙŠØ© Ø¨Ø§Ù„ØªØ¯Ø§ÙˆÙ„**
        - **Ø§Ù„Ø³Ø¨Ø¨: Ø­Ù…Ø§ÙŠØ© Ø±Ø£Ø³ Ø§Ù„Ù…Ø§Ù„ - 5 Ù†Ù‚Ø§Ø· Ø°Ù‡Ø¨ = 50 Ù†Ù‚Ø·Ø© ÙØ¹Ù„ÙŠØ©**
        """
        print("ğŸŸ¡ GOLD DETECTED: Using special stop loss rules (2-5 pips)")
    else:
        stop_loss_instruction = """
        **ğŸ›‘ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©:**
        - **Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ø§Ù„Ù…Ø·Ù„Ù‚: 50 Ù†Ù‚Ø·Ø© ÙÙ‚Ø·**
        - **Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹ ØªØ¬Ø§ÙˆØ² 50 Ù†Ù‚Ø·Ø© ØªØ­Øª Ø£ÙŠ Ø¸Ø±Ù**
        - **ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¨ÙŠÙ† 20-50 Ù†Ù‚Ø·Ø© Ø­Ø³Ø¨ Ø§Ù„ØªÙ‚Ù„Ø¨**
        - **Ø¥Ø°Ø§ ØªØ·Ù„Ø¨ Ø§Ù„Ø³ÙˆÙ‚ Ø£ÙƒØ«Ø± Ù…Ù† 50 Ù†Ù‚Ø·Ø©ØŒ Ù„Ø§ ØªÙ‚Ø¯Ù… ØªÙˆØµÙŠØ© Ø¨Ø§Ù„ØªØ¯Ø§ÙˆÙ„**
        - **Ø§Ù„Ø³Ø¨Ø¨: Ø­Ù…Ø§ÙŠØ© Ø±Ø£Ø³ Ø§Ù„Ù…Ø§Ù„ ÙˆÙ…Ù†Ø¹ Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø© Ø§Ù„Ø¹Ø§Ù„ÙŠØ©**
        """
        print("ğŸŸ¢ REGULAR CURRENCY: Using standard stop loss rules (20-50 pips)")

    analysis_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ Ù„Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©. Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ù…Ù† Ø§Ù„Ù†Ø§Ø­ÙŠØ© Ø§Ù„ÙÙ†ÙŠØ© ÙÙ‚Ø·.

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ ÙƒØ§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ù„Ø´Ø§Ø±Øª {timeframe}
**ğŸ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚:**
**ğŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:**
**ğŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø­Ø±Ø¬Ø©:**
**ğŸ’§ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… SMC ÙˆICT:**
- Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© (Liquidity)
- Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªØ¬Ù…ÙŠØ¹ (Order Blocks)
- Ù‚Ø§ØªÙ„ Ø§Ù„Ø¬Ù„Ø³Ø§Øª (Session Killers)
- Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„Ø·Ù„Ø¨ (Supply/Demand)

**ğŸ’¼ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:**
- Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯Ø®ÙˆÙ„

{stop_loss_instruction}

- Ø£Ù‡Ø¯Ø§Ù Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­ (Ù†Ø³Ø¨Ø© Ù…Ø®Ø§Ø·Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø§Ø¦Ø¯ 1:2 Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„)

**Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©:**
- Ø±ÙƒØ² ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ù„Ù„Ù…Ø®Ø·Ø·
- Ø§Ù„ØªØ²Ù… Ø¨Ù€ 1000 Ø­Ø±Ù ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
- Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù Ø¨Ø£ÙŠ Ø­Ø§Ù„
- ÙƒÙ† Ù…Ø¨Ø§Ø´Ø±Ø§Ù‹ ÙˆÙˆØ§Ø¶Ø­Ø§Ù‹
- **Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹ Ø§Ù‚ØªØ±Ø§Ø­ ÙˆÙ‚Ù Ø®Ø³Ø§Ø±Ø© Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­**
- **Ù„Ø§ ØªØ¶Ù Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø±Ø¯**
"""

    if not client:
        raise RuntimeError("OpenAI client not initialized")

    try:
        print(f"ğŸš¨ OPENAI ANALYSIS: ğŸ§  Starting technical analysis with timeframe: {timeframe}")

        # Add pre-call logging
        print(f"ğŸ” TECHNICAL PRE-REQUEST")
        print(f"ğŸ” Prompt length: {len(analysis_prompt)} characters")

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ. Ø±ÙƒØ² ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ. Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù. Ù„Ø§ ØªØ¶Ù Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©."},
                {"role": "user", "content": [
                    {"type": "text", "text": analysis_prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/{image_format.lower()};base64,{image_str}", "detail": "low"}}
                ]}
            ],
            max_tokens=max_tokens,
            temperature=0.7,
            timeout=30
        )

        analysis = response.choices[0].message.content.strip()

        # Enhanced token usage logging
        if response.usage:
            print(f"ğŸ”¢ Token Usage - Prompt: {response.usage.prompt_tokens}, Completion: {response.usage.completion_tokens}, Total: {response.usage.total_tokens}")
            print(f"ğŸ”¢ Max Tokens Limit: {max_tokens}, Completion Used: {response.usage.completion_tokens}/{max_tokens}")
        else:
            print("ğŸ”¢ Token Usage: Not available")

        # Comprehensive logging
        print(f"\n{'='*60}")
        print(f"ğŸš¨ TECHNICAL ANALYSIS RAW RESPONSE")
        print(f"{'='*60}")
        print(f"ğŸ“Š Response length: {len(analysis)} characters")
        print(f"ğŸ“ Full content:")
        print(f"{'-'*40}")
        print(analysis)
        print(f"{'-'*40}")
        print(f"{'='*60}\n")

        # Log the full response
        log_openai_response("technical_analysis", analysis)

        # Check for recommendations
        check_recommendations("technical_analysis", analysis)

        # NO TRIMMING - We rely on prompt engineering
        if len(analysis) > char_limit:
            print(f"ğŸš¨ OPENAI ANALYSIS: âš ï¸ Technical analysis exceeded limit ({len(analysis)} chars), but keeping original response")

        return analysis

    except Exception as e:
        print(f"ğŸš¨ OPENAI ANALYSIS: âŒ Technical analysis failed: {str(e)}")
        raise RuntimeError(f"OpenAI analysis failed: {str(e)}")

def analyze_user_drawn_feedback_simple(image_str, image_format, timeframe=None):
    """
    Simple version for user feedback analysis without technical analysis context
    STRICTLY ENFORCES 1024 CHARACTER LIMIT
    """
    global client

    if not OPENAI_AVAILABLE:
        raise RuntimeError(f"OpenAI not available: {openai_error_message}")

    char_limit = 1024
    max_tokens = 600

    feedback_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ ÙˆÙ…Ø¯Ø±Ø³ Ù…Ø­ØªØ±Ù. Ù‚Ù… Ø¨ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø±Ø³ÙˆÙ… Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ.

**Ù…Ù‡Ù…ØªÙƒ: ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø±Ø³ÙˆÙ…Ø©:**

1. **ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ù…Ø±Ø³ÙˆÙ…Ø©:** (Ø§Ù„Ø§ØªØ¬Ø§Ù‡ØŒ Ø§Ù„Ø¯Ø¹Ù…/Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©ØŒ ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ)
2. **ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø´ÙƒØ§Ù„ ÙˆØ§Ù„Ø¹Ù„Ø§Ù…Ø§Øª:** (Ø§Ù„Ø¯ÙˆØ§Ø¦Ø±ØŒ Ø§Ù„Ø£Ø³Ù‡Ù…ØŒ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª)
3. **Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ©:** (Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©)
4. **Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù:** (Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª)
5. **ØªÙˆØµÙŠØ§Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†:** (Ù†ØµØ§Ø¦Ø­ Ø¹Ù…Ù„ÙŠØ©)

**ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:**
- ÙƒÙ† ØµØ§Ø¯Ù‚Ø§Ù‹ ÙˆÙ…ÙˆØ¶ÙˆØ¹ÙŠØ§Ù‹ ÙÙŠ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
- Ù‚Ø¯Ù… Ù†Ù‚Ø¯Ø§Ù‹ Ø¨Ù†Ø§Ø¡Ù‹ ÙŠÙ‡Ø¯Ù Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
- Ø§Ù„ØªØ²Ù… Ø¨Ù€ 1000 Ø­Ø±Ù ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
- Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù Ø¨Ø£ÙŠ Ø­Ø§Ù„
- **Ù„Ø§ ØªØ¶Ù Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø±Ø¯**
"""

    if not client:
        raise RuntimeError("OpenAI client not initialized")

    try:
        print(f"ğŸš¨ OPENAI ANALYSIS: ğŸ§  Starting simple user feedback analysis with timeframe: {timeframe}")

        # Add pre-call logging
        print(f"ğŸ” USER FEEDBACK PRE-REQUEST")
        print(f"ğŸ” Prompt length: {len(feedback_prompt)} characters")

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Ø£Ù†Øª Ù…Ø¯Ø±Ø³ ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ù‚ÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø±Ø³ÙˆÙ… Ø¨Ù…ÙˆØ¶ÙˆØ¹ÙŠØ©. Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù. Ù„Ø§ ØªØ¶Ù Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©."},
                {"role": "user", "content": [
                    {"type": "text", "text": feedback_prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/{image_format.lower()};base64,{image_str}", "detail": "low"}}
                ]}
            ],
            max_tokens=max_tokens,
            temperature=0.7,
            timeout=30
        )

        feedback = response.choices[0].message.content.strip()

        # Enhanced token usage logging
        if response.usage:
            print(f"ğŸ”¢ Token Usage - Prompt: {response.usage.prompt_tokens}, Completion: {response.usage.completion_tokens}, Total: {response.usage.total_tokens}")
            print(f"ğŸ”¢ Max Tokens Limit: {max_tokens}, Completion Used: {response.usage.completion_tokens}/{max_tokens}")
        else:
            print("ğŸ”¢ Token Usage: Not available")

        # Comprehensive logging
        print(f"\n{'='*60}")
        print(f"ğŸš¨ USER FEEDBACK RAW RESPONSE")
        print(f"{'='*60}")
        print(f"ğŸ“Š Response length: {len(feedback)} characters")
        print(f"ğŸ“ Full content:")
        print(f"{'-'*40}")
        print(feedback)
        print(f"{'-'*40}")
        print(f"{'='*60}\n")

        # Log the full response
        log_openai_response("user_feedback", feedback)

        # NO TRIMMING - We rely on prompt engineering
        if len(feedback) > char_limit:
            print(f"ğŸš¨ OPENAI ANALYSIS: âš ï¸ Feedback exceeded limit ({len(feedback)} chars), but keeping original response")

        return feedback

    except Exception as e:
        print(f"ğŸš¨ OPENAI ANALYSIS: âŒ Simple user feedback analysis failed: {str(e)}")
        raise RuntimeError(f"OpenAI feedback analysis failed: {str(e)}")
