import time
import base64
import requests
import os
from PIL import Image
from io import BytesIO
from config import Config

OPENAI_AVAILABLE = False
client = None
openai_error_message = ""
openai_last_check = 0

def init_openai():
    """
    Initialize OpenAI client and test model availability.
    Sets OPENAI_AVAILABLE, client, openai_error_message, openai_last_check.
    """
    global OPENAI_AVAILABLE, client, openai_error_message, openai_last_check

    print("ğŸš¨ OPENAI INIT: Starting OpenAI initialization...")

    try:
        from openai import OpenAI
        print("ğŸš¨ OPENAI INIT: OpenAI package imported successfully")

        # Get API key from Config
        api_key = Config.OPENAI_API_KEY
        print(f"ğŸš¨ OPENAI INIT: Config.OPENAI_API_KEY = {api_key[:20]}..." if api_key else "ğŸš¨ OPENAI INIT: Config.OPENAI_API_KEY = None")
        print(f"ğŸš¨ OPENAI INIT: API Key exists: {bool(api_key)}")
        print(f"ğŸš¨ OPENAI INIT: API Key length: {len(api_key) if api_key else 0}")

        if not api_key or api_key == "your-api-key-here":
            openai_error_message = "OpenAI API key not configured"
            print(f"ğŸš¨ OPENAI INIT: âŒ API key check failed - not configured or still default")
            OPENAI_AVAILABLE = False
            return False

        print("ğŸš¨ OPENAI INIT: Creating OpenAI client...")
        client = OpenAI(api_key=api_key)
        print("ğŸš¨ OPENAI INIT: OpenAI client created successfully")

        try:
            print("ğŸš¨ OPENAI INIT: Testing model availability...")
            models = client.models.list()
            model_ids = [m.id for m in models.data]
            print(f"ğŸš¨ OPENAI INIT: Found {len(model_ids)} models")
            print(f"ğŸš¨ OPENAI INIT: First few models: {model_ids[:5]}")

            if "gpt-4o" not in model_ids:
                openai_error_message = "GPT-4o model not available in your account"
                print(f"ğŸš¨ OPENAI INIT: âŒ GPT-4o not found in available models")
                OPENAI_AVAILABLE = False
                return False

            print("ğŸš¨ OPENAI INIT: âœ… GPT-4o model found!")
            OPENAI_AVAILABLE = True
            openai_error_message = ""
            openai_last_check = time.time()
            print("ğŸš¨ OPENAI INIT: âœ… OpenAI initialized successfully!")
            return True

        except Exception as e:
            error_msg = str(e)
            print(f"ğŸš¨ OPENAI INIT: âŒ Model list error: {error_msg}")
            if "insufficient_quota" in error_msg:
                openai_error_message = "Account has no API credits. Please add funds to your OpenAI API account."
            elif "invalid_api_key" in error_msg:
                openai_error_message = "Invalid API key. Please check your OPENAI_API_KEY environment variable."
            elif "rate limit" in error_msg.lower():
                openai_error_message = "Rate limit exceeded. Please try again later."
            else:
                openai_error_message = f"OpenAI API test failed: {error_msg}"
            OPENAI_AVAILABLE = False
            return False

    except ImportError as e:
        print(f"ğŸš¨ OPENAI INIT: âŒ OpenAI package import error: {e}")
        openai_error_message = f"OpenAI package not installed: {e}"
        OPENAI_AVAILABLE = False
        return False
    except Exception as e:
        print(f"ğŸš¨ OPENAI INIT: âŒ General initialization error: {str(e)}")
        openai_error_message = f"OpenAI initialization error: {str(e)}"
        OPENAI_AVAILABLE = False
        return False

def detect_timeframe_from_image(image_str, image_format):
    """
    Detect the timeframe from the chart image
    Returns: (timeframe, error_message)
    """
    try:
        print("ğŸ•µï¸ Detecting timeframe from image...")

        system_prompt = """
        You are a precise chart image analyzer. Your ONLY task is to detect the timeframe label in the trading chart image.

        Look for text labels like:
        - 'M1', 'M5', 'M15', 'M30' (Minutes)
        - 'H1', 'H4' (Hours) 
        - 'D1' (Daily)
        - 'W1' (Weekly)
        - 'MN1' (Monthly)

        IMPORTANT:
        - Focus on the top corners or chart header area where timeframe labels are typically displayed
        - The label might be in different formats: 'M15', 'TF: M15', 'Timeframe: M15', '15m', '15M'
        - Return ONLY the timeframe code in standard format: M1, M5, M15, M30, H1, H4, D1, W1, MN1
        - If you cannot detect any timeframe, return 'UNKNOWN'
        - DO NOT provide any explanation or additional text
        - ONLY return the timeframe code or 'UNKNOWN'
        """

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "Detect the timeframe in this chart image. Return ONLY the timeframe code or 'UNKNOWN'."
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/{image_format};base64,{image_str}",
                                "detail": "low"
                            }
                        }
                    ]
                }
            ],
            max_tokens=10
        )

        detected_timeframe = response.choices[0].message.content.strip().upper()
        print(f"ğŸ•µï¸ Detected timeframe: {detected_timeframe}")

        # Validate the detected timeframe
        valid_timeframes = ['M1', 'M5', 'M15', 'M30', 'H1', 'H4', 'D1', 'W1', 'MN1']
        
        if detected_timeframe in valid_timeframes:
            return detected_timeframe, None
        else:
            error_msg = "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø·Ø§Ø± Ø²Ù…Ù†ÙŠ ÙˆØ§Ø¶Ø­ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©. ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ù…Ø®Ø·Ø· ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ (Ù…Ø«Ù„ M15, H4, D1)."
            return None, error_msg

    except Exception as e:
        print(f"ERROR: Timeframe detection failed: {str(e)}")
        error_msg = f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {str(e)}"
        return None, error_msg

def validate_timeframe_in_image(image_str, image_format, expected_timeframe):
    """
    Validate that the image contains the expected timeframe label
    Returns: (is_valid, error_message)
    """
    try:
        print(f"ğŸ•µï¸ Validating timeframe: expecting '{expected_timeframe}' in image")

        # Create system prompt for timeframe validation
        system_prompt = f"""
        You are a precise image validator. Your ONLY task is to check if the chart image contains the timeframe label '{expected_timeframe}'.

        IMPORTANT:
        - Look for text labels like 'M15', 'H4', '1H', 'D1' etc. in the chart
        - Focus on the top corners or chart header area where timeframe labels are typically displayed
        - The label might be in different formats: '{expected_timeframe}', 'TF: {expected_timeframe}', 'Timeframe: {expected_timeframe}'
        - Return ONLY 'VALID' if you clearly see '{expected_timeframe}' in the image
        - Return ONLY 'INVALID' if you don't see '{expected_timeframe}' or see a different timeframe

        DO NOT analyze the chart content, trends, or patterns.
        DO NOT provide any explanation or additional text.
        ONLY return 'VALID' or 'INVALID'.
        """

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "Check if this chart image contains the timeframe label. Return ONLY 'VALID' or 'INVALID'."
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/{image_format};base64,{image_str}",
                                "detail": "low"
                            }
                        }
                    ]
                }
            ],
            max_tokens=10
        )

        validation_result = response.choices[0].message.content.strip().upper()
        print(f"ğŸ•µï¸ Timeframe validation result: {validation_result}")

        if validation_result == "VALID":
            return True, None
        else:
            error_msg = f"âŒ Ø§Ù„Ø®Ø·Ø£: Ø§Ù„ØµÙˆØ±Ø© Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ {expected_timeframe}. ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ {expected_timeframe}."
            return False, error_msg

    except Exception as e:
        print(f"ERROR: Timeframe validation failed: {str(e)}")
        # If validation fails, proceed with analysis but log the error
        return True, None  # Fallback to allow analysis if validation fails

def analyze_with_openai(image_str, image_format, timeframe=None, previous_analysis=None, user_analysis=None, action_type="chart_analysis"):
    """
    Analyze an image or text using OpenAI with enhanced, detailed analysis.
    OPTIMIZED VERSION - minimal changes for performance
    """
    global client

    if not OPENAI_AVAILABLE:
        raise RuntimeError(f"OpenAI not available: {openai_error_message}")

    # Validate timeframe for first and second analysis (when image is provided)
    if image_str and action_type in ['first_analysis', 'second_analysis']:
        is_valid, error_msg = validate_timeframe_in_image(image_str, image_format, timeframe)
        if not is_valid:
            return error_msg

    # KEEP ALL EXISTING PROMPTS EXACTLY THE SAME - only change timeouts and image detail
    if action_type == "user_analysis_feedback":
        char_limit = 800
        analysis_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ ØµØ§Ø±Ù… ÙˆØµØ§Ø¯Ù‚. Ù‚Ù… Ø¨ØªÙ‚ÙŠÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ§Ù„ÙŠ Ø¨ØµØ¯Ù‚ ÙˆÙ…ÙˆØ¶ÙˆØ¹ÙŠØ©:

ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
{user_analysis}

**ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:**
1. Ù‚ÙŠÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙÙ†ÙŠØ© ÙˆØ§Ù„Ù…Ù†Ø·Ù‚
2. ÙƒÙ† ØµØ§Ø¯Ù‚Ù‹Ø§ ÙˆÙˆØ§Ø¶Ø­Ù‹Ø§ - Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¶Ø¹ÙŠÙÙ‹Ø§ Ø£Ùˆ Ø®Ø§Ø·Ø¦Ù‹Ø§ØŒ Ù‚Ù„ Ø°Ù„Ùƒ Ø¨ÙˆØ¶ÙˆØ­
3. Ù„Ø§ ØªØ¨Ø§Ù„Øº ÙÙŠ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©
4. Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¬Ø³ÙŠÙ…Ø© ÙÙŠ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠ
5. Ù‚Ø¯Ù… Ù†Ù‚Ø¯Ù‹Ø§ Ø¨Ù†Ø§Ø¡Ù‹ Ù…Ø¹ Ø­Ù„ÙˆÙ„ Ø¹Ù…Ù„ÙŠØ©

**Ù‡ÙŠÙƒÙ„ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…:**
### ğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ù…ÙˆØ¶ÙˆØ¹ÙŠ:
**Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙÙ†ÙŠØ©:** (Ø§Ø°ÙƒØ± Ù…Ø¯Ù‰ ØªÙˆØ§ÙÙ‚ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ø¹ Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„ÙÙ†ÙŠØ©)
**Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠ:** (Ø­Ù„Ù„ Ù‚ÙˆØ© Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ ÙˆØ§Ù„Ø±Ø¨Ø· Ø¨ÙŠÙ† Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…)
**Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:** (Ø­Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¨ÙˆØ¶ÙˆØ­ Ø¯ÙˆÙ† Ù…Ø¬Ø§Ù…Ù„Ø©)

### ğŸ¯ Ù†Ù‚Ø§Ø· ØªØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†:
1. (Ø§ÙƒØªØ¨ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ ØªØµØ­ÙŠØ­)
2. (ÙƒÙ† Ù…Ø­Ø¯Ø¯Ù‹Ø§ ÙˆÙˆØ§Ø¶Ø­Ù‹Ø§)

### ğŸ’¡ ØªÙˆØµÙŠØ§Øª Ø¹Ù…Ù„ÙŠØ©:
(Ù‚Ø¯Ù… 2-3 ØªÙˆØµÙŠØ§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ­Ù„ÙŠÙ„)

**ÙƒÙ† Ù…Ø­ØªØ±ÙÙ‹Ø§ ÙˆØµØ§Ø¯Ù‚Ù‹Ø§ - Ø§Ù„Ù‡Ø¯Ù Ù‡Ùˆ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø§Ù„ØªØ­Ø³Ù†ØŒ Ù„ÙŠØ³ Ø§Ù„Ù…Ø¬Ø§Ù…Ù„Ø©.**
**Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¶Ø¹ÙŠÙÙ‹Ø§ Ø¬Ø¯Ù‹Ø§ØŒ Ù‚Ù„ Ø°Ù„Ùƒ Ø¨ÙˆØ¶ÙˆØ­ Ù…Ø¹ Ø´Ø±Ø­ Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø¶Ø¹Ù.**
**Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù.**
"""
        max_tokens = char_limit // 2 + 50

    elif action_type == "single_analysis":
        char_limit = 1024
        analysis_prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ ÙˆÙ…ÙØµÙ„Ø§Ù‹ Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ.

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ ÙƒØ§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ù„Ø´Ø§Ø±Øª {timeframe}

**ğŸ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚:**
- ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ÙˆØ§Ù„Ø«Ø§Ù†ÙˆÙŠ
- ØªØ­Ù„ÙŠÙ„ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚ Ù…Ù† Ø§Ù„Ù‚Ù…Ù… ÙˆØ§Ù„Ù‚ÙŠØ¹Ø§Ù†

**ğŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ:**
- ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
- ØªØ­Ù„ÙŠÙ„ ØªÙØ§Ø¹Ù„ Ø§Ù„Ø³Ø¹Ø± Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª

**ğŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©:**
- Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
- Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø­Ø±Ø¬Ø© Ù„Ù„ÙƒØ³Ø± Ø£Ùˆ Ø§Ù„Ø§Ø±ØªØ¯Ø§Ø¯

**ğŸ’§ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©:**
- Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
- Ù…Ù†Ø§Ø·Ù‚ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©

**âš ï¸ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØ§Ù„Ù…Ø®Ø§Ø·Ø±:**
- Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ ØªØ¬Ù†Ø¨Ù‡Ø§
- Ø£Ù†Ù…Ø§Ø· Ø§Ù†Ø¹ÙƒØ§Ø³ Ù…Ø­ØªÙ…Ù„Ø©

**ğŸ’¼ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:**
- Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
- ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ
- Ø£Ù‡Ø¯Ø§Ù Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­
- Ù†ØµØ§Ø¦Ø­ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©

**Ø§Ù„ØªØ²Ù… Ø¨ØªÙ‚Ø¯ÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø¹Ù…Ù„ÙŠ ÙˆÙ…ÙÙŠØ¯ Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù.**
"""
        max_tokens = char_limit // 2 + 100

    elif timeframe == "H4" and previous_analysis:
        char_limit = 1024
        analysis_prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ ÙˆÙ…ÙØµÙ„Ø§Ù‹ ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ø¥Ø·Ø§Ø±ÙŠÙ† Ø§Ù„Ø²Ù…Ù†ÙŠÙŠÙ†.

Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø§Ø¨Ù‚ (15 Ø¯Ù‚ÙŠÙ‚Ø©): {previous_analysis}

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„
**1. ØªØ­Ù„ÙŠÙ„ ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ:**
- ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (38.2%, 50%, 61.8%)
- ØªÙØ§Ø¹Ù„ Ø§Ù„Ø³Ø¹Ø± Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª

**2. Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©:**
- Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
- Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø­Ø±Ø¬Ø© Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ù…Ø±Ø§Ù‚Ø¨ØªÙ‡Ø§

**3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©:**
- Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
- Ù…Ù†Ø§Ø·Ù‚ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©

**4. Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØ§Ù„Ù…Ø®Ø§Ø·Ø±:**
- ØªØ­Ø°ÙŠØ±Ø§Øª ÙŠØ¬Ø¨ ØªØ¬Ù†Ø¨Ù‡Ø§
- Ø£Ù†Ù…Ø§Ø· Ø§Ù†Ø¹ÙƒØ§Ø³ Ù…Ø­ØªÙ…Ù„Ø©

**5. Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:**
- Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
- Ù†Ù‚Ø§Ø· ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± ÙˆØ¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­
- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©

**Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù Ù…Ø¹ ØªÙ‚Ø¯ÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø¹Ù…Ù„ÙŠ ÙˆÙ…ÙÙŠØ¯.**
"""
        max_tokens = char_limit // 2 + 100

    elif action_type == "final_analysis":
        char_limit = 1024
        analysis_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ ÙˆÙ…ØªÙƒØ§Ù…Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠÙ† Ø§Ù„Ø³Ø§Ø¨Ù‚ÙŠÙ†:

Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ (M15): {previous_analysis}

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ Ù†Ù‡Ø§Ø¦ÙŠ Ù…ØªÙƒØ§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ğŸ“ˆ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©

**ğŸ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚:**
- ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ÙˆØ§Ù„Ø«Ø§Ù†ÙˆÙŠ
- ØªØ­Ù„ÙŠÙ„ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚ Ù…Ù† Ø§Ù„Ù‚Ù…Ù… ÙˆØ§Ù„Ù‚ÙŠØ¹Ø§Ù†

**ğŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø­Ø±Ø¬Ø©:**
- Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„ØªØµØ­ÙŠØ­ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (38.2%, 50%, 61.8%)
- ØªÙØ§Ø¹Ù„ Ø§Ù„Ø³Ø¹Ø± Ù…Ø¹ Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ

**ğŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:**
- Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù‚ÙˆÙŠØ© Ù„Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
- Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø­Ø±Ø¬Ø© Ù„Ù„ÙƒØ³Ø± Ø£Ùˆ Ø§Ù„Ø§Ø±ØªØ¯Ø§Ø¯

**ğŸ’§ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©:**
- Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©
- Ù…Ù†Ø§Ø·Ù‚ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©

**âš ï¸ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØ§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª:**
- Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ ØªØ¬Ù†Ø¨Ù‡Ø§
- Ø£Ù†Ù…Ø§Ø· Ø§Ù†Ø¹ÙƒØ§Ø³ Ù…Ø­ØªÙ…Ù„Ø©

**ğŸ’¼ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©:**
- Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ
- ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
- Ø£Ù‡Ø¯Ø§Ù Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­
- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©

**Ø§Ù„ØªØ²Ù… Ø¨ØªÙ‚Ø¯ÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø¹Ù…Ù„ÙŠ ÙˆÙ…ÙÙŠØ¯ Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù.**
"""
        max_tokens = char_limit // 2 + 100

    else:
        # First analysis with detailed prompt
        char_limit = 1024
        analysis_prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ ÙˆÙ…ÙØµÙ„Ø§Ù‹ Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ.

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ ÙƒØ§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ù„Ø´Ø§Ø±Øª {timeframe}

**ğŸ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚:**
- ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ÙˆØ§Ù„Ø«Ø§Ù†ÙˆÙŠ
- ØªØ­Ù„ÙŠÙ„ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚ Ù…Ù† Ø§Ù„Ù‚Ù…Ù… ÙˆØ§Ù„Ù‚ÙŠØ¹Ø§Ù†

**ğŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ:**
- ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
- ØªØ­Ù„ÙŠÙ„ ØªÙØ§Ø¹Ù„ Ø§Ù„Ø³Ø¹Ø± Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª

**ğŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©:**
- Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©
- Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø­Ø±Ø¬Ø© Ù„Ù„ÙƒØ³Ø± Ø£Ùˆ Ø§Ù„Ø§Ø±ØªØ¯Ø§Ø¯

**ğŸ’§ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©:**
- Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
- Ù…Ù†Ø§Ø·Ù‚ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©

**âš ï¸ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØ§Ù„Ù…Ø®Ø§Ø·Ø±:**
- Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ ØªØ¬Ù†Ø¨Ù‡Ø§
- Ø£Ù†Ù…Ø§Ø· Ø§Ù†Ø¹ÙƒØ§Ø³ Ù…Ø­ØªÙ…Ù„Ø©

**ğŸ’¼ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:**
- Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
- ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ
- Ø£Ù‡Ø¯Ø§Ù Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­
- Ù†ØµØ§Ø¦Ø­ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©

**Ø§Ù„ØªØ²Ù… Ø¨ØªÙ‚Ø¯ÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø¹Ù…Ù„ÙŠ ÙˆÙ…ÙÙŠØ¯ Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù.**
"""
        max_tokens = char_limit // 2 + 100

    if not client:
        raise RuntimeError("OpenAI client not initialized")

    try:
        import time
        start_time = time.time()
        
        if image_str:
            print(f"ğŸš¨ OPENAI ANALYSIS: Analyzing image with {action_type}")
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": f"Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù ÙÙŠ Ø±Ø¯Ùƒ."},
                    {"role": "user", "content": [
                        {"type": "text", "text": analysis_prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/{image_format.lower()};base64,{image_str}", "detail": "low"}}  # CHANGED: "high" â†’ "low"
                    ]}
                ],
                max_tokens=max_tokens,
                temperature=0.7,
                timeout=30  # ADDED: 30-second timeout
            )
        else:
            print(f"ğŸš¨ OPENAI ANALYSIS: Analyzing text with {action_type}")
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": f"Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù ÙÙŠ Ø±Ø¯Ùƒ."},
                    {"role": "user", "content": analysis_prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.7,
                timeout=20  # ADDED: 20-second timeout for text
            )

        analysis = response.choices[0].message.content.strip()
        processing_time = time.time() - start_time
        print(f"ğŸš¨ OPENAI ANALYSIS: âœ… Analysis completed in {processing_time:.2f}s, length: {len(analysis)} chars")

        # Keep existing retry logic but with timeout
        if len(analysis) > char_limit + 200:
            print(f"ğŸš¨ OPENAI ANALYSIS: Analysis too long ({len(analysis)}), retrying with shorter version")
            retry_prompt = f"""
Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø§Ø¨Ù‚ ÙƒØ§Ù† Ø·ÙˆÙŠÙ„Ø§Ù‹ Ø¬Ø¯Ø§Ù‹ ({len(analysis)} Ø­Ø±Ù). Ø£Ø¹Ø¯ ÙƒØªØ§Ø¨ØªÙ‡ Ù…Ø¹ Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ:

{analysis}
"""
            retry_response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": f"Ø§Ø®ØªØµØ§Ø± Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ {char_limit} Ø­Ø±Ù Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¬ÙˆÙ‡Ø± Ø§Ù„ÙÙ†ÙŠ."},
                    {"role": "user", "content": retry_prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.7,
                timeout=15  # ADDED: 15-second timeout for retry
            )
            analysis = retry_response.choices[0].message.content.strip()
            print(f"ğŸš¨ OPENAI ANALYSIS: âœ… Retry completed, new length: {len(analysis)} chars")

        return analysis

    except Exception as e:
        print(f"ğŸš¨ OPENAI ANALYSIS: âŒ Analysis failed: {str(e)}")
        raise RuntimeError(f"OpenAI analysis failed: {str(e)}")

def load_image_from_url(image_url):
    """Load and encode image from URL and return (b64string, format) or (None, None)"""
    try:
        print(f"ğŸš¨ IMAGE LOAD: Loading image from {image_url}")
        response = requests.get(image_url, timeout=10)
        if response.status_code == 200:
            img = Image.open(BytesIO(response.content))
            if img.format in ['PNG', 'JPEG', 'JPG']:
                buffered = BytesIO()
                img_format = img.format if img.format else 'JPEG'
                img.save(buffered, format=img_format)
                b64_data = base64.b64encode(buffered.getvalue()).decode("utf-8")
                print(f"ğŸš¨ IMAGE LOAD: âœ… Image loaded successfully, format: {img_format}, size: {len(b64_data)} chars")
                return b64_data, img_format
        print(f"ğŸš¨ IMAGE LOAD: âŒ Failed to load image, status: {response.status_code}")
        return None, None
    except Exception as e:
        print(f"ğŸš¨ IMAGE LOAD: âŒ Error loading image: {e}")
        return None, None

def analyze_user_drawn_analysis(image_str, image_format, timeframe=None):
    """
    Analyze a chart image with user-drawn analysis (lines, annotations, etc.)
    Provides feedback on the user's analysis and gives the correct technical analysis
    """
    global client

    if not OPENAI_AVAILABLE:
        raise RuntimeError(f"OpenAI not available: {openai_error_message}")

    char_limit = 1200  # Slightly more for combined feedback + analysis
    analysis_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ ÙˆÙ…Ø¯Ø±Ø³ Ù…Ø­ØªØ±Ù. Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø±Ø³Ù… ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø«Ù…:

**Ø§Ù„Ø¬Ø²Ø¡ 1: ØªÙ‚ÙŠÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø±Ø³ÙˆÙ…:**
- Ù‚ÙŠÙ… Ø§Ù„Ø®Ø·ÙˆØ· ÙˆØ§Ù„Ø¯ÙˆØ§Ø¦Ø± ÙˆØ§Ù„Ø§Ø´ÙƒØ§Ù„ Ø§Ù„Ù…Ø±Ø³ÙˆÙ…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
- Ø­Ø¯Ø¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª ØµØ­ÙŠØ­Ø© ØªÙ‚Ù†ÙŠØ§Ù‹
- Ø§Ø°ÙƒØ± Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ© ÙˆØ§Ù„Ø¶Ø¹Ù ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
- Ù‚Ø¯Ù… Ù†Ù‚Ø¯Ø§Ù‹ Ø¨Ù†Ø§Ø¡Ù‹ Ù„Ù„Ø±Ø³ÙˆÙ…Ø§Øª ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø±Ø³ÙˆÙ…

**Ø§Ù„Ø¬Ø²Ø¡ 2: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ø§Ù„ØµØ­ÙŠØ­:**
Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ ÙÙ†ÙŠØ§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ ÙŠØªØ¶Ù…Ù†:

### ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ù„Ø´Ø§Ø±Øª {timeframe}
**ğŸ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚**
**ğŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©**
**ğŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø­Ø±Ø¬Ø©**
**ğŸ’§ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©**
**âš ï¸ Ø§Ù„Ù…Ø®Ø§Ø·Ø± ÙˆØ§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª**
**ğŸ’¼ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©**

**Ø§Ù„ØªØ²Ù… Ø¨Ù‡Ø°Ø§ Ø§Ù„Ù‡ÙŠÙƒÙ„ ÙˆØ§Ø¬Ø¹Ù„ Ø§Ù„Ø±Ø¯ ÙˆØ§Ø¶Ø­Ø§Ù‹ ÙˆÙ…Ù†Ø¸Ù…Ø§Ù‹.**
**Ø§Ø¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ Ø±Ø¯ ÙˆØ§Ø­Ø¯ Ù…ØªØ±Ø§Ø¨Ø·.**
**Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù.**
"""
    max_tokens = char_limit // 2 + 150

    if not client:
        raise RuntimeError("OpenAI client not initialized")

    try:
        import time
        start_time = time.time()

        print(f"ğŸš¨ OPENAI ANALYSIS: Analyzing user-drawn analysis with timeframe: {timeframe}")
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": f"Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ ÙˆÙ…Ø¯Ø±Ø³. Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù ÙÙŠ Ø±Ø¯Ùƒ."},
                {"role": "user", "content": [
                    {"type": "text", "text": analysis_prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/{image_format.lower()};base64,{image_str}", "detail": "low"}}
                ]}
            ],
            max_tokens=max_tokens,
            temperature=0.7,
            timeout=30
        )

        analysis = response.choices[0].message.content.strip()
        processing_time = time.time() - start_time
        print(f"ğŸš¨ OPENAI ANALYSIS: âœ… User-drawn analysis completed in {processing_time:.2f}s, length: {len(analysis)} chars")

        return analysis

    except Exception as e:
        print(f"ğŸš¨ OPENAI ANALYSIS: âŒ User-drawn analysis failed: {str(e)}")
        raise RuntimeError(f"OpenAI analysis failed: {str(e)}")
