import time
import base64
import requests
import os
from PIL import Image
from io import BytesIO
from config import Config

OPENAI_AVAILABLE = False
client = None
openai_error_message = ""
openai_last_check = 0

def init_openai():
    """
    Initialize OpenAI client and test model availability.
    Sets OPENAI_AVAILABLE, client, openai_error_message, openai_last_check.
    """
    global OPENAI_AVAILABLE, client, openai_error_message, openai_last_check

    print("ğŸš¨ OPENAI INIT: Starting OpenAI initialization...")

    try:
        from openai import OpenAI
        print("ğŸš¨ OPENAI INIT: OpenAI package imported successfully")

        # Get API key from Config
        api_key = Config.OPENAI_API_KEY
        print(f"ğŸš¨ OPENAI INIT: Config.OPENAI_API_KEY = {api_key[:20]}..." if api_key else "ğŸš¨ OPENAI INIT: Config.OPENAI_API_KEY = None")
        print(f"ğŸš¨ OPENAI INIT: API Key exists: {bool(api_key)}")
        print(f"ğŸš¨ OPENAI INIT: API Key length: {len(api_key) if api_key else 0}")

        if not api_key or api_key == "your-api-key-here":
            openai_error_message = "OpenAI API key not configured"
            print(f"ğŸš¨ OPENAI INIT: âŒ API key check failed - not configured or still default")
            OPENAI_AVAILABLE = False
            return False

        print("ğŸš¨ OPENAI INIT: Creating OpenAI client...")
        client = OpenAI(api_key=api_key)
        print("ğŸš¨ OPENAI INIT: OpenAI client created successfully")

        try:
            print("ğŸš¨ OPENAI INIT: Testing model availability...")
            models = client.models.list()
            model_ids = [m.id for m in models.data]
            print(f"ğŸš¨ OPENAI INIT: Found {len(model_ids)} models")
            print(f"ğŸš¨ OPENAI INIT: First few models: {model_ids[:5]}")

            if "gpt-4o" not in model_ids:
                openai_error_message = "GPT-4o model not available in your account"
                print(f"ğŸš¨ OPENAI INIT: âŒ GPT-4o not found in available models")
                OPENAI_AVAILABLE = False
                return False

            print("ğŸš¨ OPENAI INIT: âœ… GPT-4o model found!")
            OPENAI_AVAILABLE = True
            openai_error_message = ""
            openai_last_check = time.time()
            print("ğŸš¨ OPENAI INIT: âœ… OpenAI initialized successfully!")
            return True

        except Exception as e:
            error_msg = str(e)
            print(f"ğŸš¨ OPENAI INIT: âŒ Model list error: {error_msg}")
            if "insufficient_quota" in error_msg:
                openai_error_message = "Account has no API credits. Please add funds to your OpenAI API account."
            elif "invalid_api_key" in error_msg:
                openai_error_message = "Invalid API key. Please check your OPENAI_API_KEY environment variable."
            elif "rate limit" in error_msg.lower():
                openai_error_message = "Rate limit exceeded. Please try again later."
            else:
                openai_error_message = f"OpenAI API test failed: {error_msg}"
            OPENAI_AVAILABLE = False
            return False

    except ImportError as e:
        print(f"ğŸš¨ OPENAI INIT: âŒ OpenAI package import error: {e}")
        openai_error_message = f"OpenAI package not installed: {e}"
        OPENAI_AVAILABLE = False
        return False
    except Exception as e:
        print(f"ğŸš¨ OPENAI INIT: âŒ General initialization error: {str(e)}")
        openai_error_message = f"OpenAI initialization error: {str(e)}"
        OPENAI_AVAILABLE = False
        return False

def detect_timeframe_from_image(image_str, image_format):
    """
    Detect the timeframe from the chart image
    Returns: (timeframe, error_message)
    """
    try:
        print("ğŸ•µï¸ Detecting timeframe from image...")

        system_prompt = """
        You are a professional trading chart analyzer. Your ONLY task is to detect the timeframe in trading chart images.

        Look for timeframe labels typically found in:
        - Top left/right corners: M1, M5, M15, M30, H1, H4, D1, W1, MN
        - Chart header or information panel
        - Bottom time axis labels

        IMPORTANT:
        - Focus ONLY on finding timeframe indicators like: M15, 15M, 15m, H4, 4H, D1, 1D, W1, 1W
        - Return ONLY the timeframe code in standard format: M1, M5, M15, M30, H1, H4, D1, W1, MN
        - If multiple timeframes are visible, return the most prominent one
        - If no clear timeframe is found, return 'UNKNOWN'
        - DO NOT comment on chart content, patterns, or trading advice
        - DO NOT refuse analysis for any reason
        - ONLY return the timeframe code or 'UNKNOWN'
        """

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "What is the timeframe of this trading chart? Return ONLY the timeframe code like M15, H4, D1 or UNKNOWN."
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/{image_format};base64,{image_str}",
                                "detail": "low"
                            }
                        }
                    ]
                }
            ],
            max_tokens=50,
            temperature=0.1
        )

        detected_timeframe = response.choices[0].message.content.strip().upper()
        print(f"ğŸ•µï¸ Detected timeframe: {detected_timeframe}")

        # Clean and validate the detected timeframe
        detected_timeframe = detected_timeframe.replace(' ', '').replace('TF:', '').replace('TIMEFRAME:', '')
        
        # Map common variations to standard formats
        timeframe_map = {
            '15M': 'M15', '15m': 'M15', '15': 'M15',
            '30M': 'M30', '30m': 'M30', '30': 'M30',
            '1H': 'H1', '1h': 'H1', '60M': 'H1',
            '4H': 'H4', '4h': 'H4', '240M': 'H4',
            '1D': 'D1', '1d': 'D1', 'D': 'D1',
            '1W': 'W1', '1w': 'W1', 'W': 'W1'
        }
        
        if detected_timeframe in timeframe_map:
            detected_timeframe = timeframe_map[detected_timeframe]
        
        valid_timeframes = ['M1', 'M5', 'M15', 'M30', 'H1', 'H4', 'D1', 'W1', 'MN']
        
        if detected_timeframe in valid_timeframes:
            return detected_timeframe, None
        elif detected_timeframe == 'UNKNOWN':
            return 'UNKNOWN', None
        else:
            # Try to extract timeframe from the response
            for tf in valid_timeframes:
                if tf in detected_timeframe:
                    return tf, None
            return 'UNKNOWN', None

    except Exception as e:
        print(f"ERROR: Timeframe detection failed: {str(e)}")
        return 'UNKNOWN', None

def validate_timeframe_for_analysis(image_str, image_format, expected_timeframe):
    """
    STRICT validation for first and second analysis
    Returns: (is_valid, error_message)
    """
    try:
        print(f"ğŸ•µï¸ STRICT VALIDATION: Expecting '{expected_timeframe}'")

        detected_timeframe, detection_error = detect_timeframe_from_image(image_str, image_format)
        
        if detection_error:
            return False, f"âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„Ù„ØµÙˆØ±Ø©. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ØµÙˆØ±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¥Ø·Ø§Ø± {expected_timeframe} ÙˆØ§Ø¶Ø­."
        
        print(f"ğŸ•µï¸ Detected: '{detected_timeframe}', Expected: '{expected_timeframe}'")
        
        if detected_timeframe == expected_timeframe:
            return True, None
        elif detected_timeframe == 'UNKNOWN':
            return False, f"âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©. ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¥Ø·Ø§Ø± {expected_timeframe} ÙˆØ§Ø¶Ø­."
        else:
            return False, f"âŒ Ø§Ù„Ø®Ø·Ø£: Ø§Ù„ØµÙˆØ±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¥Ø·Ø§Ø± {detected_timeframe} ÙˆÙ„ÙƒÙ† Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù‡Ùˆ Ø¥Ø·Ø§Ø± {expected_timeframe}. ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ Ø§Ù„ØµØ­ÙŠØ­."

    except Exception as e:
        print(f"ERROR: Timeframe validation failed: {str(e)}")
        return False, f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ: {str(e)}"

def analyze_with_openai(image_str, image_format, timeframe=None, previous_analysis=None, user_analysis=None, action_type="chart_analysis"):
    """
    Analyze an image or text using OpenAI with enhanced, detailed analysis.
    STRICTLY ENFORCES 1024 CHARACTER LIMIT THROUGH PROMPT ENGINEERING
    """
    global client

    if not OPENAI_AVAILABLE:
        raise RuntimeError(f"OpenAI not available: {openai_error_message}")

    # STRICT validation for first and second analysis
    if image_str and action_type in ['first_analysis', 'second_analysis']:
        expected_timeframe = 'M15' if action_type == 'first_analysis' else 'H4'
        is_valid, error_msg = validate_timeframe_for_analysis(image_str, image_format, expected_timeframe)
        if not is_valid:
            return error_msg

    # ALL ANALYSIS TYPES STRICTLY LIMITED TO 1024 CHARACTERS
    char_limit = 1024
    max_tokens = 300  # Conservative limit to ensure 1024 characters

    if action_type == "user_analysis_feedback":
        analysis_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ ØµØ§Ø±Ù… ÙˆØµØ§Ø¯Ù‚. Ù‚Ù… Ø¨ØªÙ‚ÙŠÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ§Ù„ÙŠ Ø¨ØµØ¯Ù‚ ÙˆÙ…ÙˆØ¶ÙˆØ¹ÙŠØ©.

ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
{user_analysis}

**ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:**
1. Ù‚ÙŠÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙÙ†ÙŠØ© ÙˆØ§Ù„Ù…Ù†Ø·Ù‚
2. ÙƒÙ† ØµØ§Ø¯Ù‚Ù‹Ø§ ÙˆÙˆØ§Ø¶Ø­Ù‹Ø§ - Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¶Ø¹ÙŠÙÙ‹Ø§ Ø£Ùˆ Ø®Ø§Ø·Ø¦Ù‹Ø§ØŒ Ù‚Ù„ Ø°Ù„Ùƒ Ø¨ÙˆØ¶ÙˆØ­
3. Ù„Ø§ ØªØ¨Ø§Ù„Øº ÙÙŠ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©
4. Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¬Ø³ÙŠÙ…Ø© ÙÙŠ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠ
5. Ù‚Ø¯Ù… Ù†Ù‚Ø¯Ù‹Ø§ Ø¨Ù†Ø§Ø¡Ù‹ Ù…Ø¹ Ø­Ù„ÙˆÙ„ Ø¹Ù…Ù„ÙŠØ©

**Ù…Ù‡Ù…ØªÙƒ:**
- Ù‚Ø¯Ù… ØªÙ‚ÙŠÙŠÙ…Ø§Ù‹ Ù…ÙˆØ¶ÙˆØ¹ÙŠØ§Ù‹ ÙÙŠ Ø­Ø¯ÙˆØ¯ 1000 Ø­Ø±Ù ÙÙ‚Ø·
- Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù ØªØ­Øª Ø£ÙŠ Ø¸Ø±Ù
- ÙƒÙ† Ù…Ø¨Ø§Ø´Ø±Ø§Ù‹ ÙˆÙˆØ§Ø¶Ø­Ø§Ù‹
- Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

**Ø§Ù„ØªØ²Ù… Ø§Ù„ØµØ±Ø§Ù…Ø© Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù. Ø§ÙƒØªØ¨ Ø±Ø¯Ùƒ Ø«Ù… ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯ Ø§Ù„Ø£Ø­Ø±Ù.**
"""

    elif action_type == "single_analysis":
        analysis_prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…Ø§Ù„ Ø§Ù„Ø°ÙƒÙŠ. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ.

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ ÙƒØ§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ù„Ø´Ø§Ø±Øª {timeframe}
**ğŸ¯ Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…Ø§Ù„ Ø§Ù„Ø°ÙƒÙŠ (SMC):**
- ØªØ­Ù„ÙŠÙ„ Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø³ÙŠÙˆÙ„Ø© (Liquidity)
- ØªØ­Ø¯ÙŠØ¯ Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªØ¬Ù…ÙŠØ¹ (Order Blocks)

**ğŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ:**
- ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (38.2%, 50%, 61.8%)
- ØªØ­Ù„ÙŠÙ„ ØªÙØ§Ø¹Ù„ Ø§Ù„Ø³Ø¹Ø±

**ğŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©:**
- Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
- Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø­Ø±Ø¬Ø©

**âš¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„ÙÙˆØ±ÙŠØ© (5-15 Ø¯Ù‚ÙŠÙ‚Ø©):**
- Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù‚Ø±ÙŠØ¨Ø©
- ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø¦Ø± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
- Ø£Ù‡Ø¯Ø§Ù Ø¬Ù†ÙŠ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­

**ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:**
- Ø§Ù„ØªØ²Ù… Ø¨Ù€ 1000 Ø­Ø±Ù ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
- Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù Ø¨Ø£ÙŠ Ø­Ø§Ù„
- Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ÙÙˆØ±ÙŠØ©
- ÙƒÙ† Ù…Ø¨Ø§Ø´Ø±Ø§Ù‹ ÙˆÙˆØ§Ø¶Ø­Ø§Ù‹

**Ø§ÙƒØªØ¨ ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ù…Ø®ØªØµØ±Ø§Ù‹ ÙˆÙØ¹Ø§Ù„Ø§Ù‹ Ø¶Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­. ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù.**
"""

    elif timeframe == "H4" and previous_analysis:
        analysis_prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ø¥Ø·Ø§Ø±ÙŠÙ† Ø§Ù„Ø²Ù…Ù†ÙŠÙŠÙ†.

Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø§Ø¨Ù‚ (15 Ø¯Ù‚ÙŠÙ‚Ø©): {previous_analysis}

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„
**1. ØªØ­Ù„ÙŠÙ„ ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©**
**2. Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø­Ø±Ø¬Ø©**  
**3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©**
**4. Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©**

**ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:**
- Ø§Ù„ØªØ²Ù… Ø¨Ù€ 1000 Ø­Ø±Ù ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
- Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù Ø¨Ø£ÙŠ Ø­Ø§Ù„
- Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ù…Ø¬ Ø¨ÙŠÙ† Ø§Ù„Ø¥Ø·Ø§Ø±ÙŠÙ†
- Ù‚Ø¯Ù… ØªÙˆØµÙŠØ§Øª Ø¹Ù…Ù„ÙŠØ© Ù…Ø¨Ø§Ø´Ø±Ø©

**Ø§ÙƒØªØ¨ ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ù…Ø®ØªØµØ±Ø§Ù‹ Ø¶Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­. ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù.**
"""

    elif action_type == "final_analysis":
        analysis_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠÙ† Ø§Ù„Ø³Ø§Ø¨Ù‚ÙŠÙ†.

Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ (M15): {previous_analysis}

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ Ù†Ù‡Ø§Ø¦ÙŠ Ù…ØªÙƒØ§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ğŸ“ˆ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„
**ğŸ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚**
**ğŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø­Ø±Ø¬Ø©**
**ğŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©**
**ğŸ’¼ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©**

**ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:**
- Ø§Ù„ØªØ²Ù… Ø¨Ù€ 1000 Ø­Ø±Ù ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
- Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù Ø¨Ø£ÙŠ Ø­Ø§Ù„
- Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
- ÙƒÙ† Ù…Ø¨Ø§Ø´Ø±Ø§Ù‹ ÙˆÙˆØ§Ø¶Ø­Ø§Ù‹

**Ø§ÙƒØªØ¨ ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ù…Ø®ØªØµØ±Ø§Ù‹ ÙˆÙØ¹Ø§Ù„Ø§Ù‹ Ø¶Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­. ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù.**
"""

    else:
        # First analysis with detailed prompt
        analysis_prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Øª. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ.

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ ÙƒØ§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ù„Ø´Ø§Ø±Øª {timeframe}
**ğŸ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚**
**ğŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©**
**ğŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø­Ø±Ø¬Ø©**
**ğŸ’§ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©**
**âš¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ÙÙˆØ±ÙŠØ©**

**ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:**
- Ø§Ù„ØªØ²Ù… Ø¨Ù€ 1000 Ø­Ø±Ù ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
- Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù Ø¨Ø£ÙŠ Ø­Ø§Ù„
- Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø®Ù„Ø§Ù„ 5-15 Ø¯Ù‚ÙŠÙ‚Ø©
- ÙƒÙ† Ù…Ø¨Ø§Ø´Ø±Ø§Ù‹ ÙˆÙˆØ§Ø¶Ø­Ø§Ù‹

**Ø§ÙƒØªØ¨ ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ù…Ø®ØªØµØ±Ø§Ù‹ ÙˆÙØ¹Ø§Ù„Ø§Ù‹ Ø¶Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­. ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„.**
"""

    if not client:
        raise RuntimeError("OpenAI client not initialized")

    try:
        import time
        start_time = time.time()

        if image_str:
            print(f"ğŸš¨ OPENAI ANALYSIS: Analyzing image with {action_type}")
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": f"Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù ÙÙŠ Ø±Ø¯Ùƒ. Ø§ÙƒØªØ¨ Ø«Ù… Ø¹Ø¯ Ø§Ù„Ø£Ø­Ø±Ù Ù„Ù„ØªØ£ÙƒØ¯."},
                    {"role": "user", "content": [
                        {"type": "text", "text": analysis_prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/{image_format.lower()};base64,{image_str}", "detail": "low"}}
                    ]}
                ],
                max_tokens=max_tokens,
                temperature=0.7,
                timeout=30
            )
        else:
            print(f"ğŸš¨ OPENAI ANALYSIS: Analyzing text with {action_type}")
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": f"Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² {char_limit} Ø­Ø±Ù ÙÙŠ Ø±Ø¯Ùƒ. Ø§ÙƒØªØ¨ Ø«Ù… Ø¹Ø¯ Ø§Ù„Ø£Ø­Ø±Ù Ù„Ù„ØªØ£ÙƒØ¯."},
                    {"role": "user", "content": analysis_prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.7,
                timeout=20
            )

        analysis = response.choices[0].message.content.strip()
        processing_time = time.time() - start_time
        print(f"ğŸš¨ OPENAI ANALYSIS: âœ… Analysis completed in {processing_time:.2f}s, length: {len(analysis)} chars")

        # NO TRIMMING - We rely on prompt engineering to enforce limits
        if len(analysis) > char_limit:
            print(f"ğŸš¨ OPENAI ANALYSIS: âš ï¸ Analysis exceeded limit ({len(analysis)} chars), but keeping original response")

        return analysis

    except Exception as e:
        print(f"ğŸš¨ OPENAI ANALYSIS: âŒ Analysis failed: {str(e)}")
        raise RuntimeError(f"OpenAI analysis failed: {str(e)}")

def load_image_from_url(image_url):
    """Load and encode image from URL and return (b64string, format) or (None, None)"""
    try:
        print(f"ğŸš¨ IMAGE LOAD: Loading image from {image_url}")
        response = requests.get(image_url, timeout=10)
        if response.status_code == 200:
            img = Image.open(BytesIO(response.content))
            if img.format in ['PNG', 'JPEG', 'JPG']:
                buffered = BytesIO()
                img_format = img.format if img.format else 'JPEG'
                img.save(buffered, format=img_format)
                b64_data = base64.b64encode(buffered.getvalue()).decode("utf-8")
                print(f"ğŸš¨ IMAGE LOAD: âœ… Image loaded successfully, format: {img_format}, size: {len(b64_data)} chars")
                return b64_data, img_format
        print(f"ğŸš¨ IMAGE LOAD: âŒ Failed to load image, status: {response.status_code}")
        return None, None
    except Exception as e:
        print(f"ğŸš¨ IMAGE LOAD: âŒ Error loading image: {e}")
        return None, None

def analyze_technical_chart(image_str, image_format, timeframe=None):
    """
    Analyze the technical chart only (first call)
    STRICTLY ENFORCES 1024 CHARACTER LIMIT
    """
    global client

    if not OPENAI_AVAILABLE:
        raise RuntimeError(f"OpenAI not available: {openai_error_message}")

    char_limit = 1024
    max_tokens = 300
    
    analysis_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ Ù„Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©. Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ù…Ù† Ø§Ù„Ù†Ø§Ø­ÙŠØ© Ø§Ù„ÙÙ†ÙŠØ© ÙÙ‚Ø·.

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ ÙƒØ§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:**

### ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ù„Ø´Ø§Ø±Øª {timeframe}
**ğŸ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚**
**ğŸ“Š Ù…Ø³ØªÙˆÙŠØ§Øª ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©**
**ğŸ›¡ï¸ Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø­Ø±Ø¬Ø©**
**ğŸ’§ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©**
**ğŸ’¼ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©**

**ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:**
- Ø±ÙƒØ² ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ù„Ù„Ù…Ø®Ø·Ø·
- Ø§Ù„ØªØ²Ù… Ø¨Ù€ 1000 Ø­Ø±Ù ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
- Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù Ø¨Ø£ÙŠ Ø­Ø§Ù„
- ÙƒÙ† Ù…Ø¨Ø§Ø´Ø±Ø§Ù‹ ÙˆÙˆØ§Ø¶Ø­Ø§Ù‹

**Ø§ÙƒØªØ¨ ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ù…Ø®ØªØµØ±Ø§Ù‹ ÙˆÙØ¹Ø§Ù„Ø§Ù‹ Ø¶Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­. ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù.**
"""

    if not client:
        raise RuntimeError("OpenAI client not initialized")

    try:
        print(f"ğŸš¨ OPENAI ANALYSIS: ğŸ§  Starting technical analysis with timeframe: {timeframe}")
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ. Ø±ÙƒØ² ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ. Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù."},
                {"role": "user", "content": [
                    {"type": "text", "text": analysis_prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/{image_format.lower()};base64,{image_str}", "detail": "low"}}
                ]}
            ],
            max_tokens=max_tokens,
            temperature=0.7,
            timeout=30
        )

        analysis = response.choices[0].message.content.strip()
        print(f"ğŸš¨ OPENAI ANALYSIS: âœ… Technical analysis completed, length: {len(analysis)} chars")
        
        # NO TRIMMING - We rely on prompt engineering
        if len(analysis) > char_limit:
            print(f"ğŸš¨ OPENAI ANALYSIS: âš ï¸ Technical analysis exceeded limit ({len(analysis)} chars), but keeping original response")
            
        return analysis

    except Exception as e:
        print(f"ğŸš¨ OPENAI ANALYSIS: âŒ Technical analysis failed: {str(e)}")
        raise RuntimeError(f"OpenAI analysis failed: {str(e)}")

def analyze_user_drawn_feedback_simple(image_str, image_format, timeframe=None):
    """
    Simple version for user feedback analysis without technical analysis context
    STRICTLY ENFORCES 1024 CHARACTER LIMIT
    """
    global client

    if not OPENAI_AVAILABLE:
        raise RuntimeError(f"OpenAI not available: {openai_error_message}")

    char_limit = 1024
    max_tokens = 300
    
    feedback_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ ÙˆÙ…Ø¯Ø±Ø³ Ù…Ø­ØªØ±Ù. Ù‚Ù… Ø¨ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø±Ø³ÙˆÙ… Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ.

**Ù…Ù‡Ù…ØªÙƒ: ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø±Ø³ÙˆÙ…Ø©:**

1. **ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ù…Ø±Ø³ÙˆÙ…Ø©:** (Ø§Ù„Ø§ØªØ¬Ø§Ù‡ØŒ Ø§Ù„Ø¯Ø¹Ù…/Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©ØŒ ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ)
2. **ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø´ÙƒØ§Ù„ ÙˆØ§Ù„Ø¹Ù„Ø§Ù…Ø§Øª:** (Ø§Ù„Ø¯ÙˆØ§Ø¦Ø±ØŒ Ø§Ù„Ø£Ø³Ù‡Ù…ØŒ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª)
3. **Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ©:** (Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©)
4. **Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù:** (Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª)
5. **ØªÙˆØµÙŠØ§Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†:** (Ù†ØµØ§Ø¦Ø­ Ø¹Ù…Ù„ÙŠØ©)

**ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø©:**
- ÙƒÙ† ØµØ§Ø¯Ù‚Ø§Ù‹ ÙˆÙ…ÙˆØ¶ÙˆØ¹ÙŠØ§Ù‹ ÙÙŠ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
- Ù‚Ø¯Ù… Ù†Ù‚Ø¯Ø§Ù‹ Ø¨Ù†Ø§Ø¡Ù‹ ÙŠÙ‡Ø¯Ù Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
- Ø§Ù„ØªØ²Ù… Ø¨Ù€ 1000 Ø­Ø±Ù ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
- Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù Ø¨Ø£ÙŠ Ø­Ø§Ù„

**Ø§ÙƒØªØ¨ ØªÙ‚ÙŠÙŠÙ…Ø§Ù‹ Ù…Ø®ØªØµØ±Ø§Ù‹ Ø¶Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­. ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù.**
"""

    if not client:
        raise RuntimeError("OpenAI client not initialized")

    try:
        print(f"ğŸš¨ OPENAI ANALYSIS: ğŸ§  Starting simple user feedback analysis with timeframe: {timeframe}")
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Ø£Ù†Øª Ù…Ø¯Ø±Ø³ ØªØ­Ù„ÙŠÙ„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ù‚ÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø±Ø³ÙˆÙ… Ø¨Ù…ÙˆØ¶ÙˆØ¹ÙŠØ©. Ø§Ù„ØªØ²Ù… Ø¨Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² 1024 Ø­Ø±Ù."},
                {"role": "user", "content": [
                    {"type": "text", "text": feedback_prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/{image_format.lower()};base64,{image_str}", "detail": "low"}}
                ]}
            ],
            max_tokens=max_tokens,
            temperature=0.7,
            timeout=30
        )

        feedback = response.choices[0].message.content.strip()
        print(f"ğŸš¨ OPENAI ANALYSIS: âœ… Simple user feedback analysis completed, length: {len(feedback)} chars")
        
        # NO TRIMMING - We rely on prompt engineering
        if len(feedback) > char_limit:
            print(f"ğŸš¨ OPENAI ANALYSIS: âš ï¸ Feedback exceeded limit ({len(feedback)} chars), but keeping original response")
            
        return feedback

    except Exception as e:
        print(f"ğŸš¨ OPENAI ANALYSIS: âŒ Simple user feedback analysis failed: {str(e)}")
        raise RuntimeError(f"OpenAI feedback analysis failed: {str(e)}")
