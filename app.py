import os
import base64
import re
import requests
import json
from flask import Flask, request, jsonify
from PIL import Image
from io import BytesIO
import time
from datetime import datetime, timedelta

# ØªÙ‡ÙŠØ¦Ø© Flask
app = Flask(__name__)

# ØªØ­Ø¯ÙŠØ¯ Ø­Ø¬Ù… Ø£Ù‚ØµÙ‰ Ù„Ù„Ø±ÙØ¹ (5MB)
app.config['MAX_CONTENT_LENGTH'] = 5 * 1024 * 1024

# ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª (ÙÙŠ production Ø§Ø³ØªØ®Ø¯Ù… Redis Ø£Ùˆ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª)
analysis_sessions = {}

# ØªÙ‡ÙŠØ¦Ø© OpenAI Client
OPENAI_AVAILABLE = False
client = None
openai_error_message = ""
openai_last_check = 0

def init_openai():
    """Initialize OpenAI client with error handling"""
    global OPENAI_AVAILABLE, client, openai_error_message, openai_last_check

    try:
        from openai import OpenAI
        api_key = os.getenv("OPENAI_API_KEY")

        if not api_key or api_key == "your-api-key-here":
            openai_error_message = "OpenAI API key not configured"
            return False

        client = OpenAI(api_key=api_key)

        # Test the API with a simple request
        try:
            models = client.models.list()
            # Check if gpt-4o is available
            model_ids = [model.id for model in models.data]
            if "gpt-4o" not in model_ids:
                openai_error_message = "GPT-4o model not available in your account"
                return False

            OPENAI_AVAILABLE = True
            openai_error_message = ""
            openai_last_check = time.time()
            return True

        except Exception as e:
            error_msg = str(e)
            if "insufficient_quota" in error_msg:
                openai_error_message = "Account has no API credits. Please add funds to your OpenAI API account."
            elif "invalid_api_key" in error_msg:
                openai_error_message = "Invalid API key. Please check your OPENAI_API_KEY environment variable."
            else:
                openai_error_message = f"OpenAI API test failed: {error_msg}"
            return False

    except ImportError:
        openai_error_message = "OpenAI package not installed"
        return False
    except Exception as e:
        openai_error_message = f"OpenAI initialization error: {str(e)}"
        return False

# Initialize OpenAI on startup
init_openai()

[Odef is_complete_response(response_text):
    """Check if the response seems complete with more precise criteria"""
    if not response_text or len(response_text.strip()) < 150:  # Increased minimum length
        return False
    
    # Check if the response ends with a complete sentence
    last_char = response_text.strip()[-1]
    if last_char not in ['.', '!', '?', ':', ';', 'ØŒ', ')', ']', '}']:
        return False
    
    # Check for specific incomplete patterns
    incomplete_patterns = [
        r'\(Stop-L', r'\(Take-P', r'\(SL', r'\(TP', 
        r'Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©', r'ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©', r'Ø£Ø®Ø° Ø§Ù„Ø±Ø¨Ø­',
        r'...', r'â€¦', r'\.\.\.'
    ]
    
    for pattern in incomplete_patterns:
        if re.search(pattern, response_text[-20:]):  # Check last 20 characters
            return False
    
    # Check if all key sections are present
    key_sections = ['Ø§Ù„Ø§ØªØ¬Ø§Ù‡', 'Ø§Ù„Ø¯Ø¹Ù…', 'Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©', 'Ø§Ù„Ø¯Ø®ÙˆÙ„', 'Ø§Ù„Ø®Ø±ÙˆØ¬', 'Ø§Ù„Ù…Ø®Ø§Ø·Ø±']
    found_sections = sum(1 for section in key_sections if section in response_text)
    
    return found_sections >= 4  # At least 4 out of 6 key sections

def analyze_with_openai(image_str, image_format, timeframe=None, previous_analysis=None):
    """Analyze image with OpenAI with enhanced prompt to avoid truncation"""
    
    if timeframe == "H4" and previous_analysis:
        analysis_prompt = f"""
Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ ÙˆØ§Ø¶Ø­Ø§Ù‹ ÙˆØ´Ø§Ù…Ù„Ø§Ù‹ Ù„Ù„Ø´Ø§Ø±Øª Ø§Ù„Ù…Ø¹Ø±ÙˆØ¶ Ù„Ù„Ø¥Ø·Ø§Ø± 4 Ø³Ø§Ø¹Ø§Øª.

Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ù„Ø¥Ø·Ø§Ø± 15 Ø¯Ù‚ÙŠÙ‚Ø©:
{previous_analysis}

Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ§Ù„ÙŠØ© ÙÙŠ ØªØ­Ù„ÙŠÙ„Ùƒ:
1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚
2. ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
3. ØªØ­Ù„ÙŠÙ„ Ù…Ø¤Ø´Ø± RSI ÙˆØ§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„Ù…ØªØ­Ø±ÙƒØ©
4. ØªØ­Ø¯ÙŠØ¯ Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØ§Ù„Ø®Ø±ÙˆØ¬ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
5. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± ÙˆÙ†Ø³Ø¨ Ø§Ù„Ù…ÙƒØ§ÙØ£Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©

**Ù…Ù„Ø§Ø­Ø¸Ø© Ù…Ù‡Ù…Ø©**: ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ØªØ­Ù„ÙŠÙ„Ùƒ Ù…ÙƒØªÙ…Ù„Ø§Ù‹ ÙˆÙ„Ø§ ÙŠÙ†Ù‚Ø·Ø¹ ÙØ¬Ø£Ø©. ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ù†Ù‡Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ù…Ù„ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­.
"""
    else:
        analysis_prompt = """
Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ ÙˆØ§Ø¶Ø­Ø§Ù‹ ÙˆØ´Ø§Ù…Ù„Ø§Ù‹ Ù„Ù„Ø´Ø§Ø±Øª Ø§Ù„Ù…Ø¹Ø±ÙˆØ¶ Ù„Ù„Ø¥Ø·Ø§Ø± 15 Ø¯Ù‚ÙŠÙ‚Ø©.

Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ§Ù„ÙŠØ© ÙÙŠ ØªØ­Ù„ÙŠÙ„Ùƒ:
1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø³ÙˆÙ‚
2. ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
3. ØªØ­Ù„ÙŠÙ„ Ù…Ø¤Ø´Ø± RSI Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø±Ø¦ÙŠØ§Ù‹
4. ØªØ­Ø¯ÙŠØ¯ Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØ§Ù„Ø®Ø±ÙˆØ¬ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
5. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

**Ù…Ù„Ø§Ø­Ø¸Ø© Ù…Ù‡Ù…Ø©**: ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ØªØ­Ù„ÙŠÙ„Ùƒ Ù…ÙƒØªÙ…Ù„Ø§Ù‹ ÙˆÙ„Ø§ ÙŠÙ†Ù‚Ø·Ø¹ ÙØ¬Ø£Ø©. ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ù†Ù‡Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ù…Ù„ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­.
"""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ ÙÙ†ÙŠ Ù…Ø­ØªØ±Ù. Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø¯Ù‚ÙŠÙ‚Ø§Ù‹ ÙˆØ¹Ù…Ù„ÙŠØ§Ù‹ Ø¨Ù„ØºØ© ÙˆØ§Ø¶Ø­Ø©. ØªØ£ÙƒØ¯ Ù…Ù† Ø¥ÙƒÙ…Ø§Ù„ Ø¬Ù…ÙŠØ¹ Ø£Ù‚Ø³Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ¹Ø¯Ù… Ù‚Ø·Ø¹ Ø§Ù„Ø±Ø¯ ÙØ¬Ø£Ø©. Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù„Ù„ØªØ¯Ø§ÙˆÙ„."
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": analysis_prompt
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/{image_format.lower()};base64,{image_str}",
                            "detail": "high"
                        }
                    }
                ]
            }
        ],
        max_tokens=3000,  # Reduced to avoid excessive token usage
        temperature=0.7
    )

    return response.choices[0].message.content.strip()

@app.route('/')
def home():
    status = "âœ…" if OPENAI_AVAILABLE else "âŒ"
    return f"XFLEXAI Server is running {status} - OpenAI: {'Available' if OPENAI_AVAILABLE else openai_error_message}"

# New endpoint for multi-timeframe analysis
@app.route('/multi-timeframe-analyze', methods=['POST'])
def multi_timeframe_analyze():
    """
    Handle multi-timeframe analysis with session management
    """
    try:
        data = request.get_json()

        if not data:
            return jsonify({
                "message": "Ù„Ù… ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª",
                "analysis": "ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: Ù„Ù… ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª"
            }), 400

        user_id = data.get('user_id', 'default_user')
        image_url = data.get('last_message') or data.get('image_url')
        timeframe = data.get('timeframe')

        if not image_url:
            return jsonify({
                "message": "Ù„Ù… ÙŠØªÙ… ØªÙ‚Ø¯ÙŠÙ… Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙˆØ±Ø©",
                "analysis": "ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: Ù„Ù… ÙŠØªÙ… ØªÙ‚Ø¯ÙŠÙ… Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙˆØ±Ø©"
            }), 400

        # Initialize user session if not exists
        if user_id not in analysis_sessions:
            analysis_sessions[user_id] = {
                'm15_analysis': None,
                'h4_analysis': None,
                'created_at': datetime.now(),
                'status': 'awaiting_m15'
            }

        session = analysis_sessions[user_id]

        # Download and process image
        response = requests.get(image_url, timeout=10)
        if response.status_code != 200:
            return jsonify({
                "message": "ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©",
                "analysis": "ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©"
            }), 400

        img = Image.open(BytesIO(response.content))

        if img.format not in ['PNG', 'JPEG', 'JPG']:
            return jsonify({
                "message": "Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…",
                "analysis": "ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…"
            }), 400

        if not OPENAI_AVAILABLE:
            return jsonify({
                "message": "Ø®Ø¯Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©",
                "analysis": f"ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {openai_error_message}"
            }), 503

        # Convert image to base64
        buffered = BytesIO()
        img_format = img.format if img.format else 'JPEG'
        img.save(buffered, format=img_format)
        img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")

        # Determine which analysis to perform
        if session['status'] == 'awaiting_m15' or not timeframe:
            # First image - assume M15
            analysis = analyze_with_openai(img_str, img_format, "M15")
            
            # Check if response is complete
            if not is_complete_response(analysis):
                # Instead of retrying, add a note about incomplete sections
                incomplete_sections = []
                if 'Ø§Ù„Ù…Ø®Ø§Ø·Ø±' not in analysis or 'Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©' not in analysis:
                    incomplete_sections.append("Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±")
                if 'Ø§Ù„Ø¯Ø®ÙˆÙ„' not in analysis or 'Ø§Ù„Ø®Ø±ÙˆØ¬' not in analysis:
                    incomplete_sections.append("Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØ§Ù„Ø®Ø±ÙˆØ¬")
                
                if incomplete_sections:
                    completion_note = f"\n\nâš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„ØªØ­Ù„ÙŠÙ„ ØºÙŠØ± Ù…ÙƒØªÙ…Ù„ ÙÙŠ Ù‚Ø³Ù… {', '.join(incomplete_sections)}. ÙŠÙˆØµÙ‰ Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù‚Ø§Ø· ÙŠØ¯ÙˆÙŠØ§Ù‹."
                    analysis += completion_note
                
            session['m15_analysis'] = analysis
            session['status'] = 'awaiting_h4'

            return jsonify({
                "message": "âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ø±Øª 15 Ø¯Ù‚ÙŠÙ‚Ø© Ø¨Ù†Ø¬Ø§Ø­",
                "analysis": analysis,
                "next_step": "Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ ØµÙˆØ±Ø© Ø§Ù„Ø¥Ø·Ø§Ø± 4 Ø³Ø§Ø¹Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„",
                "status": "awaiting_h4",
                "user_id": user_id
            }), 200

        elif session['status'] == 'awaiting_h4' and timeframe == "H4":
            # Second image - H4 with comprehensive analysis
            analysis = analyze_with_openai(img_str, img_format, "H4", session['m15_analysis'])
            
            # Check if response is complete
            if not is_complete_response(analysis):
                # Instead of retrying, add a note about incomplete sections
                incomplete_sections = []
                if 'Ø§Ù„Ù…Ø®Ø§Ø·Ø±' not in analysis or 'Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©' not in analysis:
                    incomplete_sections.append("Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±")
                if 'Ø§Ù„Ø¯Ø®ÙˆÙ„' not in analysis or 'Ø§Ù„Ø®Ø±ÙˆØ¬' not in analysis:
                    incomplete_sections.append("Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØ§Ù„Ø®Ø±ÙˆØ¬")
                
                if incomplete_sections:
                    completion_note = f"\n\nâš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„ØªØ­Ù„ÙŠÙ„ ØºÙŠØ± Ù…ÙƒØªÙ…Ù„ ÙÙŠ Ù‚Ø³Ù… {', '.join(incomplete_sections)}. ÙŠÙˆØµÙ‰ Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù‚Ø§Ø· ÙŠØ¯ÙˆÙŠØ§Ù‹."
                    analysis += completion_note
                
            session['h4_analysis'] = analysis
            session['status'] = 'completed'

            # Prepare final comprehensive analysis
            final_analysis = f"""
## ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø± Ø§Ù„Ø²Ù…Ù†ÙŠØ©

### ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø·Ø§Ø± 15 Ø¯Ù‚ÙŠÙ‚Ø©:
{session['m15_analysis']}

### ğŸ•“ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø·Ø§Ø± 4 Ø³Ø§Ø¹Ø§Øª:
{analysis}

### ğŸ¯ Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:
Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ Ù„Ù„Ø¥Ø·Ø§Ø±ÙŠÙ†ØŒ ÙŠØªÙ… ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:
- Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ø«Ù„Ù‰
- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
- Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
"""

            # Clean up session after completion
            del analysis_sessions[user_id]

            return jsonify({
                "message": "âœ… ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ø¨Ù†Ø¬Ø§Ø­",
                "analysis": final_analysis,
                "status": "completed"
            }), 200

        else:
            return jsonify({
                "message": "Ø®Ø·Ø£ ÙÙŠ ØªØ³Ù„Ø³Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„",
                "analysis": "Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø¨Ø¯Ø¡ Ø¨Ø¥Ø±Ø³Ø§Ù„ ØµÙˆØ±Ø© Ø§Ù„Ø¥Ø·Ø§Ø± 15 Ø¯Ù‚ÙŠÙ‚Ø© Ø£ÙˆÙ„Ø§Ù‹"
            }), 400

    except Exception as e:
        return jsonify({
            "message": f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}",
            "analysis": f"ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}"
        }), 400

# Keep the original endpoint for backward compatibility
@app.route('/sendpulse-analyze', methods=['POST'])
def sendpulse_analyze():
    """
    Backward compatibility endpoint - redirects to multi-timeframe analysis
    """
    return multi_timeframe_analyze()

@app.route('/status')
def status():
    """Endpoint to check API status"""
    if time.time() - openai_last_check > 300:
        init_openai()

    return jsonify({
        "server": "running",
        "openai_available": OPENAI_AVAILABLE,
        "openai_error": openai_error_message,
        "active_sessions": len(analysis_sessions),
        "timestamp": time.time()
    })

@app.route('/clear-sessions')
def clear_sessions():
    """Clear all analysis sessions (for debugging)"""
    global analysis_sessions
    count = len(analysis_sessions)
    analysis_sessions = {}
    return jsonify({
        "message": f"ØªÙ… Ù…Ø³Ø­ {count} Ø¬Ù„Ø³Ø©",
        "status": "sessions_cleared"
    })

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)
